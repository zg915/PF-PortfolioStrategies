{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import uniform, beta, norm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import skew, kurtosis\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_descriptive_statistics(data):\n",
    "    \"\"\"\n",
    "    Calculate descriptive statistics for each column in the dataset.\n",
    "    \n",
    "    Parameters:\n",
    "        data (pd.DataFrame): DataFrame with numerical data for each index.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing Mean, Std. Dev., Skew, and Kurtosis.\n",
    "    \"\"\"\n",
    "    stats = {\n",
    "        \"Mean\": data.mean(),\n",
    "        \"Std. Dev.\": data.std(),\n",
    "        \"Skew\": data.apply(skew),\n",
    "        \"Kurtosis\": data.apply(lambda x: kurtosis(x, fisher=True))  # Fisher=True gives excess kurtosis\n",
    "    }\n",
    "    \n",
    "    return pd.DataFrame(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USE</th>\n",
       "      <th>USSC</th>\n",
       "      <th>UST</th>\n",
       "      <th>USB</th>\n",
       "      <th>LTB</th>\n",
       "      <th>BB</th>\n",
       "      <th>USR</th>\n",
       "      <th>GC</th>\n",
       "      <th>BC</th>\n",
       "      <th>TSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-12-01</th>\n",
       "      <td>0.408015</td>\n",
       "      <td>0.027108</td>\n",
       "      <td>-0.993055</td>\n",
       "      <td>1.812880</td>\n",
       "      <td>3.124899</td>\n",
       "      <td>0.468406</td>\n",
       "      <td>3.701063</td>\n",
       "      <td>-10.662434</td>\n",
       "      <td>-2.894356</td>\n",
       "      <td>0.405998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01</th>\n",
       "      <td>5.301067</td>\n",
       "      <td>7.668438</td>\n",
       "      <td>8.833362</td>\n",
       "      <td>1.239524</td>\n",
       "      <td>0.237975</td>\n",
       "      <td>1.602843</td>\n",
       "      <td>7.558280</td>\n",
       "      <td>11.395481</td>\n",
       "      <td>3.688525</td>\n",
       "      <td>5.667619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-01</th>\n",
       "      <td>4.340577</td>\n",
       "      <td>2.568956</td>\n",
       "      <td>6.410042</td>\n",
       "      <td>-1.277254</td>\n",
       "      <td>-2.829941</td>\n",
       "      <td>-0.202221</td>\n",
       "      <td>-1.150725</td>\n",
       "      <td>-2.964978</td>\n",
       "      <td>5.353938</td>\n",
       "      <td>4.218455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-01</th>\n",
       "      <td>2.766024</td>\n",
       "      <td>2.171514</td>\n",
       "      <td>4.874998</td>\n",
       "      <td>-1.573824</td>\n",
       "      <td>-4.224694</td>\n",
       "      <td>-0.497515</td>\n",
       "      <td>4.361363</td>\n",
       "      <td>-1.320834</td>\n",
       "      <td>-1.773539</td>\n",
       "      <td>2.627505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-04-01</th>\n",
       "      <td>-0.232274</td>\n",
       "      <td>-1.316574</td>\n",
       "      <td>-1.001722</td>\n",
       "      <td>2.499252</td>\n",
       "      <td>4.801574</td>\n",
       "      <td>1.003277</td>\n",
       "      <td>3.686116</td>\n",
       "      <td>-0.148032</td>\n",
       "      <td>-1.354158</td>\n",
       "      <td>-0.210375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-01</th>\n",
       "      <td>3.195099</td>\n",
       "      <td>-1.399620</td>\n",
       "      <td>6.301166</td>\n",
       "      <td>1.215946</td>\n",
       "      <td>1.825939</td>\n",
       "      <td>0.877783</td>\n",
       "      <td>0.624706</td>\n",
       "      <td>-0.134700</td>\n",
       "      <td>-0.171899</td>\n",
       "      <td>2.714648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-01</th>\n",
       "      <td>1.537427</td>\n",
       "      <td>10.643647</td>\n",
       "      <td>-1.521827</td>\n",
       "      <td>2.890084</td>\n",
       "      <td>3.654331</td>\n",
       "      <td>2.353104</td>\n",
       "      <td>9.281175</td>\n",
       "      <td>5.367196</td>\n",
       "      <td>-2.798104</td>\n",
       "      <td>2.252879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-01</th>\n",
       "      <td>2.336556</td>\n",
       "      <td>-1.688551</td>\n",
       "      <td>1.103867</td>\n",
       "      <td>1.349349</td>\n",
       "      <td>2.095666</td>\n",
       "      <td>1.453755</td>\n",
       "      <td>5.220651</td>\n",
       "      <td>2.092249</td>\n",
       "      <td>-2.081485</td>\n",
       "      <td>2.131556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-01</th>\n",
       "      <td>1.788252</td>\n",
       "      <td>0.368044</td>\n",
       "      <td>2.477588</td>\n",
       "      <td>1.386692</td>\n",
       "      <td>2.007479</td>\n",
       "      <td>1.317310</td>\n",
       "      <td>2.407239</td>\n",
       "      <td>5.088851</td>\n",
       "      <td>0.723654</td>\n",
       "      <td>1.717074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-01</th>\n",
       "      <td>-0.588365</td>\n",
       "      <td>-1.080598</td>\n",
       "      <td>-0.725319</td>\n",
       "      <td>-3.382326</td>\n",
       "      <td>-5.452729</td>\n",
       "      <td>-2.446154</td>\n",
       "      <td>-2.542702</td>\n",
       "      <td>4.299349</td>\n",
       "      <td>1.436909</td>\n",
       "      <td>-0.446041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 USE       USSC       UST       USB       LTB        BB  \\\n",
       "Date                                                                      \n",
       "2011-12-01  0.408015   0.027108 -0.993055  1.812880  3.124899  0.468406   \n",
       "2012-01-01  5.301067   7.668438  8.833362  1.239524  0.237975  1.602843   \n",
       "2012-02-01  4.340577   2.568956  6.410042 -1.277254 -2.829941 -0.202221   \n",
       "2012-03-01  2.766024   2.171514  4.874998 -1.573824 -4.224694 -0.497515   \n",
       "2012-04-01 -0.232274  -1.316574 -1.001722  2.499252  4.801574  1.003277   \n",
       "...              ...        ...       ...       ...       ...       ...   \n",
       "2024-06-01  3.195099  -1.399620  6.301166  1.215946  1.825939  0.877783   \n",
       "2024-07-01  1.537427  10.643647 -1.521827  2.890084  3.654331  2.353104   \n",
       "2024-08-01  2.336556  -1.688551  1.103867  1.349349  2.095666  1.453755   \n",
       "2024-09-01  1.788252   0.368044  2.477588  1.386692  2.007479  1.317310   \n",
       "2024-10-01 -0.588365  -1.080598 -0.725319 -3.382326 -5.452729 -2.446154   \n",
       "\n",
       "                 USR         GC        BC       TSE  \n",
       "Date                                                 \n",
       "2011-12-01  3.701063 -10.662434 -2.894356  0.405998  \n",
       "2012-01-01  7.558280  11.395481  3.688525  5.667619  \n",
       "2012-02-01 -1.150725  -2.964978  5.353938  4.218455  \n",
       "2012-03-01  4.361363  -1.320834 -1.773539  2.627505  \n",
       "2012-04-01  3.686116  -0.148032 -1.354158 -0.210375  \n",
       "...              ...        ...       ...       ...  \n",
       "2024-06-01  0.624706  -0.134700 -0.171899  2.714648  \n",
       "2024-07-01  9.281175   5.367196 -2.798104  2.252879  \n",
       "2024-08-01  5.220651   2.092249 -2.081485  2.131556  \n",
       "2024-09-01  2.407239   5.088851  0.723654  1.717074  \n",
       "2024-10-01 -2.542702   4.299349  1.436909 -0.446041  \n",
       "\n",
       "[155 rows x 10 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of yfinance-compatible tickers\n",
    "tickers = [\n",
    "    \"SPY\",      # S&P 500 ETF (large-cap U.S. equities)\n",
    "    \"IWM\",      # iShares Russell 2000 ETF (small-cap U.S. equities)\n",
    "    \"QQQ\",      # Nasdaq 100 ETF (tech-heavy U.S. equities)\n",
    "    \"IEF\",      # iShares 7-10 Year Treasury Bond ETF (intermediate bonds)\n",
    "    \"TLT\",      # iShares 20+ Year Treasury Bond ETF (long-term bonds)\n",
    "    \"BND\",      # Vanguard Total Bond Market ETF (broad bond market)\n",
    "    \"VNQ\",      # Vanguard Real Estate ETF (U.S. REITs)\n",
    "    \"GLD\",      # SPDR Gold Shares (gold commodity)\n",
    "    \"DBC\",      # Invesco DB Commodity Index Tracking Fund (broad commodities)\n",
    "    \"VTI\"       # Vanguard Total Stock Market ETF (overall U.S. equities)\n",
    "]\n",
    "\n",
    "# Download monthly returns data for the last 14 years\n",
    "start_date = \"2011-11-01\"\n",
    "end_date = \"2024-11-01\"\n",
    "\n",
    "# Fetch monthly data for each ticker\n",
    "monthly_returns = {}\n",
    "for ticker in tickers:\n",
    "    data = yf.download(ticker, start=start_date, end=end_date, interval='1mo', progress=False)['Adj Close']\n",
    "    returns = data.pct_change().dropna() * 100  # Calculate monthly returns\n",
    "    monthly_returns[ticker] = returns\n",
    "\n",
    "# Combine all into a single DataFrame\n",
    "monthly_returns_df = pd.DataFrame(monthly_returns)\n",
    "monthly_returns_df.index.name = \"Date\"\n",
    "\n",
    "# Abbreviation mapping for tickers\n",
    "abbreviation_mapping = {\n",
    "    \"SPY\": \"USE\",     # Large-cap U.S. equities\n",
    "    \"IWM\": \"USSC\",    # Small-cap U.S. equities\n",
    "    \"QQQ\": \"UST\",     # Technology-focused U.S. equities\n",
    "    \"IEF\": \"USB\",     # Intermediate-term U.S. bonds\n",
    "    \"TLT\": \"LTB\",     # Long-term U.S. bonds\n",
    "    \"BND\": \"BB\",      # Broad U.S. bond market\n",
    "    \"VNQ\": \"USR\",     # U.S. REITs\n",
    "    \"GLD\": \"GC\",      # Gold commodity\n",
    "    \"DBC\": \"BC\",      # Broad commodities\n",
    "    \"VTI\": \"TSE\"      # Total U.S. equities\n",
    "}\n",
    "\n",
    "# Rename columns based on the abbreviation mapping\n",
    "monthly_returns_df.rename(columns=abbreviation_mapping, inplace=True)\n",
    "monthly_returns_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std. Dev.</th>\n",
       "      <th>Skew</th>\n",
       "      <th>Kurtosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>USE</th>\n",
       "      <td>1.223233</td>\n",
       "      <td>4.144438</td>\n",
       "      <td>-0.444681</td>\n",
       "      <td>0.978387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USSC</th>\n",
       "      <td>0.971101</td>\n",
       "      <td>5.501756</td>\n",
       "      <td>-0.333031</td>\n",
       "      <td>1.637728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UST</th>\n",
       "      <td>1.598465</td>\n",
       "      <td>5.009285</td>\n",
       "      <td>-0.273878</td>\n",
       "      <td>0.221404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USB</th>\n",
       "      <td>0.117529</td>\n",
       "      <td>1.868574</td>\n",
       "      <td>0.037401</td>\n",
       "      <td>0.112869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LTB</th>\n",
       "      <td>0.131238</td>\n",
       "      <td>3.904732</td>\n",
       "      <td>0.319343</td>\n",
       "      <td>0.167585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BB</th>\n",
       "      <td>0.152360</td>\n",
       "      <td>1.392525</td>\n",
       "      <td>-0.028788</td>\n",
       "      <td>1.141847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USR</th>\n",
       "      <td>0.800214</td>\n",
       "      <td>5.064624</td>\n",
       "      <td>-0.412084</td>\n",
       "      <td>1.282603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GC</th>\n",
       "      <td>0.351601</td>\n",
       "      <td>4.363482</td>\n",
       "      <td>0.188758</td>\n",
       "      <td>-0.083944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BC</th>\n",
       "      <td>0.039117</td>\n",
       "      <td>4.790997</td>\n",
       "      <td>-0.398904</td>\n",
       "      <td>0.449247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSE</th>\n",
       "      <td>1.201381</td>\n",
       "      <td>4.253102</td>\n",
       "      <td>-0.459499</td>\n",
       "      <td>1.213139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Mean  Std. Dev.      Skew  Kurtosis\n",
       "USE   1.223233   4.144438 -0.444681  0.978387\n",
       "USSC  0.971101   5.501756 -0.333031  1.637728\n",
       "UST   1.598465   5.009285 -0.273878  0.221404\n",
       "USB   0.117529   1.868574  0.037401  0.112869\n",
       "LTB   0.131238   3.904732  0.319343  0.167585\n",
       "BB    0.152360   1.392525 -0.028788  1.141847\n",
       "USR   0.800214   5.064624 -0.412084  1.282603\n",
       "GC    0.351601   4.363482  0.188758 -0.083944\n",
       "BC    0.039117   4.790997 -0.398904  0.449247\n",
       "TSE   1.201381   4.253102 -0.459499  1.213139"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate Descriptive Statistics\n",
    "descriptive_stats = calculate_descriptive_statistics(monthly_returns_df)\n",
    "descriptive_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USE</th>\n",
       "      <th>USSC</th>\n",
       "      <th>UST</th>\n",
       "      <th>USB</th>\n",
       "      <th>LTB</th>\n",
       "      <th>BB</th>\n",
       "      <th>USR</th>\n",
       "      <th>GC</th>\n",
       "      <th>BC</th>\n",
       "      <th>TSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.223233</td>\n",
       "      <td>0.971101</td>\n",
       "      <td>1.598465</td>\n",
       "      <td>0.117529</td>\n",
       "      <td>0.131238</td>\n",
       "      <td>0.152360</td>\n",
       "      <td>0.800214</td>\n",
       "      <td>0.351601</td>\n",
       "      <td>0.039117</td>\n",
       "      <td>1.201381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.144438</td>\n",
       "      <td>5.501756</td>\n",
       "      <td>5.009285</td>\n",
       "      <td>1.868574</td>\n",
       "      <td>3.904732</td>\n",
       "      <td>1.392525</td>\n",
       "      <td>5.064624</td>\n",
       "      <td>4.363482</td>\n",
       "      <td>4.790997</td>\n",
       "      <td>4.253102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-12.998732</td>\n",
       "      <td>-21.779559</td>\n",
       "      <td>-13.488935</td>\n",
       "      <td>-4.737245</td>\n",
       "      <td>-9.442612</td>\n",
       "      <td>-4.192765</td>\n",
       "      <td>-20.016045</td>\n",
       "      <td>-11.058839</td>\n",
       "      <td>-17.340184</td>\n",
       "      <td>-14.311355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.802328</td>\n",
       "      <td>-1.986510</td>\n",
       "      <td>-1.502412</td>\n",
       "      <td>-1.020461</td>\n",
       "      <td>-2.557437</td>\n",
       "      <td>-0.549809</td>\n",
       "      <td>-2.524590</td>\n",
       "      <td>-2.507565</td>\n",
       "      <td>-2.981861</td>\n",
       "      <td>-0.945027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.701163</td>\n",
       "      <td>1.214503</td>\n",
       "      <td>1.996835</td>\n",
       "      <td>0.031522</td>\n",
       "      <td>-0.035009</td>\n",
       "      <td>0.112023</td>\n",
       "      <td>1.127501</td>\n",
       "      <td>-0.167167</td>\n",
       "      <td>-0.038801</td>\n",
       "      <td>1.734416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.479714</td>\n",
       "      <td>4.215610</td>\n",
       "      <td>4.816796</td>\n",
       "      <td>1.218858</td>\n",
       "      <td>2.267531</td>\n",
       "      <td>0.868345</td>\n",
       "      <td>3.693589</td>\n",
       "      <td>2.960073</td>\n",
       "      <td>3.455202</td>\n",
       "      <td>3.498233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13.361051</td>\n",
       "      <td>18.244171</td>\n",
       "      <td>15.218765</td>\n",
       "      <td>4.634434</td>\n",
       "      <td>11.045844</td>\n",
       "      <td>4.519331</td>\n",
       "      <td>13.191192</td>\n",
       "      <td>11.395481</td>\n",
       "      <td>10.197628</td>\n",
       "      <td>13.695173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              USE        USSC         UST         USB         LTB          BB  \\\n",
       "count  155.000000  155.000000  155.000000  155.000000  155.000000  155.000000   \n",
       "mean     1.223233    0.971101    1.598465    0.117529    0.131238    0.152360   \n",
       "std      4.144438    5.501756    5.009285    1.868574    3.904732    1.392525   \n",
       "min    -12.998732  -21.779559  -13.488935   -4.737245   -9.442612   -4.192765   \n",
       "25%     -0.802328   -1.986510   -1.502412   -1.020461   -2.557437   -0.549809   \n",
       "50%      1.701163    1.214503    1.996835    0.031522   -0.035009    0.112023   \n",
       "75%      3.479714    4.215610    4.816796    1.218858    2.267531    0.868345   \n",
       "max     13.361051   18.244171   15.218765    4.634434   11.045844    4.519331   \n",
       "\n",
       "              USR          GC          BC         TSE  \n",
       "count  155.000000  155.000000  155.000000  155.000000  \n",
       "mean     0.800214    0.351601    0.039117    1.201381  \n",
       "std      5.064624    4.363482    4.790997    4.253102  \n",
       "min    -20.016045  -11.058839  -17.340184  -14.311355  \n",
       "25%     -2.524590   -2.507565   -2.981861   -0.945027  \n",
       "50%      1.127501   -0.167167   -0.038801    1.734416  \n",
       "75%      3.693589    2.960073    3.455202    3.498233  \n",
       "max     13.191192   11.395481   10.197628   13.695173  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly_returns_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USE</th>\n",
       "      <th>USSC</th>\n",
       "      <th>UST</th>\n",
       "      <th>USB</th>\n",
       "      <th>LTB</th>\n",
       "      <th>BB</th>\n",
       "      <th>USR</th>\n",
       "      <th>GC</th>\n",
       "      <th>BC</th>\n",
       "      <th>TSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.223233</td>\n",
       "      <td>0.971101</td>\n",
       "      <td>1.598465</td>\n",
       "      <td>0.117529</td>\n",
       "      <td>0.131238</td>\n",
       "      <td>0.152360</td>\n",
       "      <td>0.800214</td>\n",
       "      <td>0.351601</td>\n",
       "      <td>0.039117</td>\n",
       "      <td>1.201381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.144438</td>\n",
       "      <td>5.501756</td>\n",
       "      <td>5.009285</td>\n",
       "      <td>1.868574</td>\n",
       "      <td>3.904732</td>\n",
       "      <td>1.392525</td>\n",
       "      <td>5.064624</td>\n",
       "      <td>4.363482</td>\n",
       "      <td>4.790997</td>\n",
       "      <td>4.253102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-12.998732</td>\n",
       "      <td>-21.779559</td>\n",
       "      <td>-13.488935</td>\n",
       "      <td>-4.737245</td>\n",
       "      <td>-9.442612</td>\n",
       "      <td>-4.192765</td>\n",
       "      <td>-20.016045</td>\n",
       "      <td>-11.058839</td>\n",
       "      <td>-17.340184</td>\n",
       "      <td>-14.311355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.802328</td>\n",
       "      <td>-1.986510</td>\n",
       "      <td>-1.502412</td>\n",
       "      <td>-1.020461</td>\n",
       "      <td>-2.557437</td>\n",
       "      <td>-0.549809</td>\n",
       "      <td>-2.524590</td>\n",
       "      <td>-2.507565</td>\n",
       "      <td>-2.981861</td>\n",
       "      <td>-0.945027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.701163</td>\n",
       "      <td>1.214503</td>\n",
       "      <td>1.996835</td>\n",
       "      <td>0.031522</td>\n",
       "      <td>-0.035009</td>\n",
       "      <td>0.112023</td>\n",
       "      <td>1.127501</td>\n",
       "      <td>-0.167167</td>\n",
       "      <td>-0.038801</td>\n",
       "      <td>1.734416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.479714</td>\n",
       "      <td>4.215610</td>\n",
       "      <td>4.816796</td>\n",
       "      <td>1.218858</td>\n",
       "      <td>2.267531</td>\n",
       "      <td>0.868345</td>\n",
       "      <td>3.693589</td>\n",
       "      <td>2.960073</td>\n",
       "      <td>3.455202</td>\n",
       "      <td>3.498233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13.361051</td>\n",
       "      <td>18.244171</td>\n",
       "      <td>15.218765</td>\n",
       "      <td>4.634434</td>\n",
       "      <td>11.045844</td>\n",
       "      <td>4.519331</td>\n",
       "      <td>13.191192</td>\n",
       "      <td>11.395481</td>\n",
       "      <td>10.197628</td>\n",
       "      <td>13.695173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              USE        USSC         UST         USB         LTB          BB  \\\n",
       "count  155.000000  155.000000  155.000000  155.000000  155.000000  155.000000   \n",
       "mean     1.223233    0.971101    1.598465    0.117529    0.131238    0.152360   \n",
       "std      4.144438    5.501756    5.009285    1.868574    3.904732    1.392525   \n",
       "min    -12.998732  -21.779559  -13.488935   -4.737245   -9.442612   -4.192765   \n",
       "25%     -0.802328   -1.986510   -1.502412   -1.020461   -2.557437   -0.549809   \n",
       "50%      1.701163    1.214503    1.996835    0.031522   -0.035009    0.112023   \n",
       "75%      3.479714    4.215610    4.816796    1.218858    2.267531    0.868345   \n",
       "max     13.361051   18.244171   15.218765    4.634434   11.045844    4.519331   \n",
       "\n",
       "              USR          GC          BC         TSE  \n",
       "count  155.000000  155.000000  155.000000  155.000000  \n",
       "mean     0.800214    0.351601    0.039117    1.201381  \n",
       "std      5.064624    4.363482    4.790997    4.253102  \n",
       "min    -20.016045  -11.058839  -17.340184  -14.311355  \n",
       "25%     -2.524590   -2.507565   -2.981861   -0.945027  \n",
       "50%      1.127501   -0.167167   -0.038801    1.734416  \n",
       "75%      3.693589    2.960073    3.455202    3.498233  \n",
       "max     13.191192   11.395481   10.197628   13.695173  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly_returns_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel:\n",
    "    \"\"\"\n",
    "    Base class for all models, providing shared functionality, variables, parameters, and methods.\n",
    "    \"\"\"\n",
    "    def __init__(self, observation, num_particles = 1_000_000, time_steps = 155):\n",
    "        \"\"\"Initialize base model parameters, variables, and shared functions.\"\"\"\n",
    "        self.observation = observation.values  # Y = returns.values\n",
    "        self.L = num_particles  # Number of particles\n",
    "        self.T = time_steps  # Number of time steps\n",
    "        self.Î´ = 0.98\n",
    "        self.Î±_shrink_factor = (3 * self.Î´ - 1) / (2 * self.Î´)\n",
    "        self.train = self.observation[:48]\n",
    "\n",
    "        # Common variables\n",
    "        self.variables = {\n",
    "            \"x\": np.zeros((self.T, self.L)),  # Latent x\n",
    "            \"p_x\": np.zeros((self.T, self.L)), # particles of latent x, shape (T, L)\n",
    "            \"xÌ„\": np.zeros((self.T, self.L)),\n",
    "            \"p_xÌ„\":np.zeros((self.T, self.L)),\n",
    "            \"Ï•_x\":np.zeros((self.T, self.L)),\n",
    "            \"p_Ï•_x\":np.zeros((self.T, self.L)),\n",
    "            \"Ïƒ_x\": np.zeros((self.T, self.L)),\n",
    "            \"p_Ïƒ_x\":np.zeros((self.T, self.L)),\n",
    "\n",
    "            \"Î±\":np.zeros((self.T, self.L)),\n",
    "            \"y\": np.zeros((self.T, self.L)),  # Estimated return\n",
    "            \"Î¾\": np.zeros((self.T, self.L)),\n",
    "            \"Ïµ\":np.zeros((self.T, self.L)),\n",
    "        }\n",
    "            \n",
    "    @staticmethod\n",
    "    def N(mean, variance, size=None):\n",
    "        \"\"\"Generate samples from a normal distribution.\"\"\"\n",
    "        return np.random.normal(mean, np.sqrt(variance), size)\n",
    "\n",
    "    @staticmethod\n",
    "    def U(start_point, end_point, size=None):\n",
    "        \"\"\"Generate samples from a uniform distribution.\"\"\"\n",
    "        return np.random.uniform(start_point, end_point, size)\n",
    "\n",
    "    @staticmethod\n",
    "    def B(Î±, Î², size=None):\n",
    "        \"\"\"Generate samples from a beta distribution.\"\"\"\n",
    "        return np.random.beta(Î±, Î², size)\n",
    "\n",
    "    @staticmethod\n",
    "    def SOSS_update(Î±, Î¸):\n",
    "        \"\"\"Perform second-order stochastic smoothing.\"\"\"\n",
    "        return BaseModel.N(Î± * Î¸ + (1 - Î±) * np.mean(Î¸), (1 - Î±**2) * np.var(Î¸))\n",
    "\n",
    "    @staticmethod\n",
    "    def x_transition_function(xÌ„, Ï•_x, Ïƒ_x, Î¾_t, x_t):\n",
    "        \"\"\"Transition function for variable x.\"\"\"\n",
    "        return xÌ„ + Ï•_x * (x_t - xÌ„) + Ïƒ_x * Î¾_t\n",
    "\n",
    "    @staticmethod\n",
    "    def observation_function(Î¼_t, x_t, Ïµ_t):\n",
    "        \"\"\"Observation function.\"\"\"\n",
    "        return Î¼_t + np.exp(x_t / 2) * Ïµ_t\n",
    "\n",
    "    @staticmethod\n",
    "    def observation_likelihood(y, Î¼, x):\n",
    "        \"\"\"Calculate the observation likelihood.\"\"\"\n",
    "        Ïƒ_t = np.exp(x / 2)\n",
    "        return (1 / (np.sqrt(2 * np.pi) * Ïƒ_t)) * np.exp(-((y - Î¼) ** 2) / (2 * Ïƒ_t**2))\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_stats(data):\n",
    "        median = np.median(data, axis=1)\n",
    "        lower_percentile = np.percentile(data, 2.5, axis=1)\n",
    "        upper_percentile = np.percentile(data, 97.5, axis=1)\n",
    "        return median, lower_percentile, upper_percentile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CMSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CMSVModel(BaseModel):\n",
    "    \"\"\"\n",
    "    CMSV Model class.\n",
    "    \"\"\"\n",
    "    def __init__(self, observation, num_particles, time_steps, Î²=0.8):\n",
    "        super().__init__(observation, num_particles, time_steps)\n",
    "        # Variables\n",
    "        self.variables.update({\n",
    "            \"Î¼Ì„\":np.zeros((self.T, self.L)),\n",
    "            \"p_Î¼Ì„\":np.zeros((self.T, self.L)),\n",
    "        })\n",
    "\n",
    "        # Initialization\n",
    "        self.variables[\"Î¼Ì„\"][0] = self.U(-5, 5, self.L)\n",
    "        self.variables[\"xÌ„\"][0] = self.U(-1, 5, self.L)\n",
    "        self.variables[\"Ï•_x\"][0] = 2 * self.B(20, 1.5, self.L) - 1\n",
    "        self.variables[\"Ïƒ_x\"][0] = self.U(0, 2, self.L)\n",
    "        \n",
    "        self.variables[\"x\"][0] = self.N(\n",
    "            self.variables[\"xÌ„\"][0], \n",
    "            (self.variables[\"Ïƒ_x\"][0] ** 2) / (1 - self.variables[\"Ï•_x\"][0] ** 2)\n",
    "        )\n",
    "        self.variables[\"Ïµ\"][0] = self.N(0, 1, self.L)\n",
    "        self.variables[\"y\"][0] = self.observation_function(\n",
    "            self.variables[\"Î¼Ì„\"][0], self.variables[\"x\"][0], self.variables[\"Ïµ\"][0]\n",
    "        )\n",
    "\n",
    "    def particle_filtering(self):\n",
    "        \"\"\"Particle filtering process for state estimation.\"\"\"\n",
    "        for t in tqdm(range(1, self.T)):\n",
    "            # SOSS update for prior estimates\n",
    "            self.variables[\"p_xÌ„\"][t] = self.SOSS_update(self.Î±_shrink_factor, self.variables[\"xÌ„\"][t - 1])\n",
    "            self.variables[\"p_Ï•_x\"][t] = self.SOSS_update(self.Î±_shrink_factor, self.variables[\"Ï•_x\"][t - 1])\n",
    "            self.variables[\"p_Ïƒ_x\"][t] = self.SOSS_update(self.Î±_shrink_factor, self.variables[\"Ïƒ_x\"][t - 1])\n",
    "            self.variables[\"p_Î¼Ì„\"][t] = self.SOSS_update(self.Î±_shrink_factor, self.variables[\"Î¼Ì„\"][t - 1])\n",
    "\n",
    "            # Generate system noise and calculate particles for x\n",
    "            self.variables[\"Î¾\"][t] = self.N(0, 1, self.L)\n",
    "            self.variables[\"p_x\"][t] = self.x_transition_function(\n",
    "                self.variables[\"p_xÌ„\"][t],\n",
    "                self.variables[\"p_Ï•_x\"][t],\n",
    "                self.variables[\"p_Ïƒ_x\"][t],\n",
    "                self.variables[\"Î¾\"][t],\n",
    "                self.variables[\"x\"][t - 1],\n",
    "            )\n",
    "\n",
    "            # Generate observation noise and calculate expected observations\n",
    "            self.variables[\"Ïµ\"][t] = self.N(0, 1, self.L)\n",
    "            self.variables[\"y\"][t] = self.observation_function(\n",
    "                self.variables[\"p_Î¼Ì„\"][t], self.variables[\"p_x\"][t], self.variables[\"Ïµ\"][t]\n",
    "            )\n",
    "\n",
    "            # Calculate likelihood using Gaussian observation likelihood\n",
    "            self.variables[\"Î±\"][t] = self.observation_likelihood(self.observation[t], self.variables[\"p_Î¼Ì„\"][t], self.variables[\"p_x\"][t])\n",
    "\n",
    "            # Normalize the likelihood to calculate weights\n",
    "            weights = self.variables[\"Î±\"][t]\n",
    "            weights /= np.sum(self.variables[\"Î±\"][t])\n",
    "\n",
    "            # Resample particles based on weights\n",
    "            cumulative_sum = np.cumsum(weights)\n",
    "            positions = (np.arange(self.L) + np.random.uniform(0, 1)) / self.L\n",
    "            sample_indices = np.searchsorted(cumulative_sum, positions)\n",
    "\n",
    "            # Resample all variables\n",
    "            self.variables[\"x\"][t] = self.variables[\"p_x\"][t, sample_indices]\n",
    "            self.variables[\"xÌ„\"][t] = self.variables[\"p_xÌ„\"][t, sample_indices]\n",
    "            self.variables[\"Î¼Ì„\"][t] = self.variables[\"p_Î¼Ì„\"][t, sample_indices]\n",
    "            self.variables[\"Ï•_x\"][t] = self.variables[\"p_Ï•_x\"][t, sample_indices]\n",
    "            self.variables[\"Ïƒ_x\"][t] = self.variables[\"p_Ïƒ_x\"][t, sample_indices]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SMSVModel(BaseModel):\n",
    "    \"\"\"\n",
    "    SMSV Model class.\n",
    "    \"\"\"\n",
    "    def __init__(self, observation, num_particles, time_steps, Î²=0.8):\n",
    "        super().__init__(observation, num_particles, time_steps)\n",
    "\n",
    "        # Variables\n",
    "        self.variables.update({\n",
    "            'Î¼':np.zeros((self.T, self.L)),\n",
    "            \"p_Î¼\":np.zeros((self.T, self.L)),\n",
    "            \"Î¼Ì„\":np.zeros((self.T, self.L)),\n",
    "            \"p_Î¼Ì„\":np.zeros((self.T, self.L)),\n",
    "            \"Ïƒ_Î¼\": np.zeros((self.T, self.L)),\n",
    "            \"p_Ï•_Î¼\":np.zeros((self.T, self.L)),\n",
    "            \"Ïƒ_Î¼\":np.zeros((self.T, self.L)),\n",
    "            \"p_Ïƒ_Î¼\":np.zeros((self.T, self.L)),\n",
    "            \"Î·\": np.zeros((self.T, self.L)),\n",
    "        })\n",
    "\n",
    "        # Initialization\n",
    "        self.variables[\"Î¼Ì„\"][0] = self.U(-5, 5, self.L)\n",
    "        self.variables[\"xÌ„\"][0] = self.U(-1, 5, self.L)\n",
    "        self.variables[\"Ï•_Î¼\"][0] = self.U(0, 1, self.L)\n",
    "        self.variables[\"Ïƒ_Î¼\"][0] = self.U(0, np.std(self.train), self.L)\n",
    "        self.variables[\"Ï•_x\"][0] = 2 * self.B(20, 1.5, self.L) - 1\n",
    "        self.variables[\"Ïƒ_x\"][0] = self.U(0, 2, self.L)\n",
    "        self.variables[\"x\"][0] = self.N(\n",
    "            self.variables[\"xÌ„\"][0], \n",
    "            (self.variables[\"Ïƒ_x\"][0] ** 2) / (1 - self.variables[\"Ï•_x\"][0] ** 2)\n",
    "        )\n",
    "        self.variables[\"Î¼\"][0] = self.N(\n",
    "            self.variables[\"Î¼Ì„\"][0], \n",
    "            (self.variables[\"Ïƒ_Î¼\"][0] ** 2) / (1 - self.variables[\"Ïƒ_Î¼\"][0] ** 2)\n",
    "        )        \n",
    "        \n",
    "        self.variables[\"Ïµ\"][0] = self.N(0, 1, self.L)\n",
    "        self.variables[\"y\"][0] = self.observation_function(\n",
    "            self.variables[\"Î¼\"][0], self.variables[\"x\"][0], self.variables[\"Ïµ\"][0]\n",
    "        )\n",
    "\n",
    "    # functions\n",
    "    def Î¼_transition_function(Î¼Ì„, Ï•_Î¼, Ïƒ_Î¼, Î·_Î¼, Î¼_t):\n",
    "        particles = Î¼Ì„ + \n",
    "        * (Î¼_t - Î¼Ì„) + Ïƒ_Î¼ * Î·_Î¼\n",
    "        return particles\n",
    "\n",
    "    def particle_filtering(self):\n",
    "        \"\"\"Particle filtering process for state estimation.\"\"\"\n",
    "        for t in tqdm(range(1, self.T)):\n",
    "            # SOSS update for prior estimates\n",
    "            self.variables[\"p_xÌ„\"][t] = self.SOSS_update(self.Î±_shrink_factor, self.variables[\"xÌ„\"][t - 1])\n",
    "            self.variables[\"p_Ï•_x\"][t] = self.SOSS_update(self.Î±_shrink_factor, self.variables[\"Ï•_x\"][t - 1])\n",
    "            self.variables[\"p_Ïƒ_x\"][t] = self.SOSS_update(self.Î±_shrink_factor, self.variables[\"Ïƒ_x\"][t - 1])\n",
    "            self.variables[\"p_Î¼Ì„\"][t] = self.SOSS_update(self.Î±_shrink_factor, self.variables[\"Î¼Ì„\"][t - 1])\n",
    "            self.variables[\"p_Ïƒ_Î¼\"][t] = self.SOSS_update(self.Î±_shrink_factor, self.variables[\"Ïƒ_Î¼\"][t - 1])\n",
    "            self.variables[\"p_Ï•_Î¼\"][t] = self.SOSS_update(self.Î±_shrink_factor, self.variables[\"Ï•_Î¼\"][t - 1])\n",
    "\n",
    "            # Generate system noise and calculate particles for x\n",
    "            self.variables[\"Î¾\"][t] = self.N(0, 1, self.L)\n",
    "            self.variables[\"p_x\"][t] = self.x_transition_function(\n",
    "                self.variables[\"p_xÌ„\"][t],\n",
    "                self.variables[\"p_Ï•_x\"][t],\n",
    "                self.variables[\"p_Ïƒ_x\"][t],\n",
    "                self.variables[\"Î¾\"][t],\n",
    "                self.variables[\"x\"][t - 1],\n",
    "            )\n",
    "\n",
    "            # Generate system noise and calculate particles for Î¼\n",
    "            self.variables[\"Î·\"][t] = self.N(0, 1, self.L)\n",
    "            self.variables[\"p_Î¼\"][t] = self.Î¼_transition_function(\n",
    "                self.variables[\"p_Î¼Ì„\"][t],\n",
    "                self.variables[\"p_Ï•_Î¼\"][t],\n",
    "                self.variables[\"p_Ïƒ_Î¼\"][t],\n",
    "                self.variables[\"Î·\"][t],\n",
    "                self.variables[\"Î¼\"][t - 1],\n",
    "            )\n",
    "\n",
    "            # Generate observation noise and calculate expected observations\n",
    "            self.variables[\"Ïµ\"][t] = self.N(0, 1, self.L)\n",
    "            self.variables[\"y\"][t] = self.observation_function(\n",
    "                self.variables[\"p_Î¼\"][t], self.variables[\"p_x\"][t], self.variables[\"Ïµ\"][t]\n",
    "            )\n",
    "\n",
    "            # Calculate likelihood using Gaussian observation likelihood\n",
    "            likelihood = self.observation_likelihood(self.observation[t], self.variables[\"p_Î¼\"][t], self.variables[\"p_x\"][t])\n",
    "            self.variables[\"Î±\"][t] = likelihood\n",
    "\n",
    "            # Normalize the likelihood to calculate weights\n",
    "            weights = self.variables[\"Î±\"][t]\n",
    "            weights /= np.sum(weights)\n",
    "\n",
    "            # Resample particles based on weights\n",
    "            cumulative_sum = np.cumsum(weights)\n",
    "            positions = (np.arange(self.L) + np.random.uniform(0, 1)) / self.L\n",
    "            sample_indices = np.searchsorted(cumulative_sum, positions)\n",
    "\n",
    "            # Resample all variables\n",
    "            self.variables[\"x\"][t] = self.variables[\"p_x\"][t, sample_indices]\n",
    "            self.variables[\"Î¼\"][t] = self.variables[\"p_Î¼\"][t, sample_indices]\n",
    "            self.variables[\"xÌ„\"][t] = self.variables[\"p_xÌ„\"][t, sample_indices]\n",
    "            self.variables[\"Î¼Ì„\"][t] = self.variables[\"p_Î¼Ì„\"][t, sample_indices]\n",
    "            self.variables[\"Ï•_x\"][t] = self.variables[\"p_Ï•_x\"][t, sample_indices]\n",
    "            self.variables[\"Ïƒ_x\"][t] = self.variables[\"p_Ïƒ_x\"][t, sample_indices]\n",
    "            self.variables[\"Ï•_Î¼\"][t] = self.variables[\"p_Ï•_Î¼\"][t, sample_indices]\n",
    "            self.variables[\"Ïƒ_Î¼\"][t] = self.variables[\"p_Ïƒ_Î¼\"][t, sample_indices]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMSV_EMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SMSV_EMAModel(BaseModel):\n",
    "    \"\"\"\n",
    "    SMSV_EMA Model class.\n",
    "    \"\"\"\n",
    "    def __init__(self, observation, num_particles, time_steps, Î²=0.8):\n",
    "        super().__init__(observation, num_particles, time_steps)\n",
    "        # Parameter\n",
    "        self.Î±_Î¼_parameter = np.full(self.L, np.mean(observation[:24]))\n",
    "        self.Ï•_Î¼ = np.full(self.L, 1 - self.Î²)# shape (L, 1)\n",
    "        self.Ïƒ_Î¼ = self.U(0, self.calculate_Ïƒ_Î¼(self.Î±_Î¼_parameter, self.observation, self.Î²), self.L)\n",
    "        \n",
    "        # Initialization\n",
    "        self.variables[\"xÌ„\"][0] = self.U(-1, 5, self.L)\n",
    "        self.variables[\"Ï•_x\"][0] = 2 * self.B(20, 1.5, self.L) - 1\n",
    "        self.variables[\"Ïƒ_x\"][0] = self.U(0, 2, self.L)\n",
    "        \n",
    "        self.variables[\"x\"][0] = self.N(\n",
    "            self.variables[\"xÌ„\"][0], \n",
    "            (self.variables[\"Ïƒ_x\"][0] ** 2) / (1 - self.variables[\"Ï•_x\"][0] ** 2)\n",
    "        )\n",
    "        self.variables[\"Î¼\"][0] = self.N(\n",
    "            self.Î±_Î¼_parameter, \n",
    "            (self.variables[\"Ïƒ_Î¼\"][0] ** 2) / (1 - self.variables[\"Ïƒ_Î¼\"][0] ** 2)\n",
    "        )   \n",
    "        self.variables[\"Ïµ\"][0] = self.N(0, 1, self.L)\n",
    "        self.variables[\"y\"][0] = self.observation_function(\n",
    "            self.variables[\"Î¼\"][0], self.variables[\"x\"][0], self.variables[\"Ïµ\"][0]\n",
    "        )\n",
    "\n",
    "    def Î¼_transition_function(y_t, Ï•_Î¼, Î¼_t):\n",
    "        particles = y_t + Ï•_Î¼ * (Î¼_t - y_t)\n",
    "        return particles\n",
    "    \n",
    "    def calculate_Ïƒ_Î¼(Î±, Y, Î²):\n",
    "        Î¼Ì„ = np.zeros(len(Y))\n",
    "        Î¼Ì„[0] = Î±[0]\n",
    "        for i in range(1, len(Y)):\n",
    "            Î¼Ì„[i] = Î² * Y[i - 1] + (1 - Î²) * Î¼Ì„[i - 1]\n",
    "        return np.std(Î¼Ì„)\n",
    "    def particle_filtering(self):\n",
    "        \"\"\"Particle filtering process for state estimation.\"\"\"\n",
    "        for t in tqdm(range(1, self.T)):\n",
    "            # SOSS update for prior estimates\n",
    "            self.variables[\"p_xÌ„\"][t] = self.SOSS_update(self.Î±_shrink_factor, self.variables[\"xÌ„\"][t - 1])\n",
    "            self.variables[\"p_Ï•_x\"][t] = self.SOSS_update(self.Î±_shrink_factor, self.variables[\"Ï•_x\"][t - 1])\n",
    "            self.variables[\"p_Ïƒ_x\"][t] = self.SOSS_update(self.Î±_shrink_factor, self.variables[\"Ïƒ_x\"][t - 1])\n",
    "            self.variables[\"p_Î¼Ì„\"][t] = self.SOSS_update(self.Î±_shrink_factor, self.variables[\"Î¼Ì„\"][t - 1])\n",
    "            self.variables[\"p_Ïƒ_Î¼\"][t] = self.SOSS_update(self.Î±_shrink_factor, self.variables[\"Ïƒ_Î¼\"][t - 1])\n",
    "            self.variables[\"p_Ï•_Î¼\"][t] = self.SOSS_update(self.Î±_shrink_factor, self.variables[\"Ï•_Î¼\"][t - 1])\n",
    "\n",
    "            # Generate system noise and calculate particles for x\n",
    "            self.variables[\"Î¾\"][t] = self.N(0, 1, self.L)\n",
    "            self.variables[\"p_x\"][t] = self.x_transition_function(\n",
    "                self.variables[\"p_xÌ„\"][t],\n",
    "                self.variables[\"p_Ï•_x\"][t],\n",
    "                self.variables[\"p_Ïƒ_x\"][t],\n",
    "                self.variables[\"Î¾\"][t],\n",
    "                self.variables[\"x\"][t - 1],\n",
    "            )\n",
    "\n",
    "            # Generate system noise and calculate particles for Î¼\n",
    "            self.variables[\"Î·\"][t] = self.N(0, 1, self.L)\n",
    "            self.variables[\"p_Î¼\"][t] = self.Î¼_transition_function(\n",
    "                self.variables[\"p_Î¼Ì„\"][t],\n",
    "                self.variables[\"p_Ï•_Î¼\"][t],\n",
    "                self.variables[\"p_Ïƒ_Î¼\"][t],\n",
    "                self.variables[\"Î·\"][t],\n",
    "                self.variables[\"Î¼\"][t - 1],\n",
    "            )\n",
    "\n",
    "            # Generate observation noise and calculate expected observations\n",
    "            self.variables[\"Ïµ\"][t] = self.N(0, 1, self.L)\n",
    "            self.variables[\"y\"][t] = self.observation_function(\n",
    "                self.variables[\"p_Î¼\"][t], self.variables[\"p_x\"][t], self.variables[\"Ïµ\"][t]\n",
    "            )\n",
    "\n",
    "            # Calculate likelihood using Gaussian observation likelihood\n",
    "            likelihood = self.observation_likelihood(self.observation[t], self.variables[\"p_Î¼\"][t], self.variables[\"p_x\"][t])\n",
    "            self.variables[\"Î±\"][t] = likelihood\n",
    "\n",
    "            # Normalize the likelihood to calculate weights\n",
    "            weights = self.variables[\"Î±\"][t]\n",
    "            weights /= np.sum(weights)\n",
    "\n",
    "            # Resample particles based on weights\n",
    "            cumulative_sum = np.cumsum(weights)\n",
    "            positions = (np.arange(self.L) + np.random.uniform(0, 1)) / self.L\n",
    "            sample_indices = np.searchsorted(cumulative_sum, positions)\n",
    "\n",
    "            # Resample all variables\n",
    "            self.variables[\"x\"][t] = self.variables[\"p_x\"][t, sample_indices]\n",
    "            self.variables[\"Î¼\"][t] = self.variables[\"p_Î¼\"][t, sample_indices]\n",
    "            self.variables[\"xÌ„\"][t] = self.variables[\"p_xÌ„\"][t, sample_indices]\n",
    "            self.variables[\"Î¼Ì„\"][t] = self.variables[\"p_Î¼Ì„\"][t, sample_indices]\n",
    "            self.variables[\"Ï•_x\"][t] = self.variables[\"p_Ï•_x\"][t, sample_indices]\n",
    "            self.variables[\"Ïƒ_x\"][t] = self.variables[\"p_Ïƒ_x\"][t, sample_indices]\n",
    "            self.variables[\"Ï•_Î¼\"][t] = self.variables[\"p_Ï•_Î¼\"][t, sample_indices]\n",
    "            self.variables[\"Ïƒ_Î¼\"][t] = self.variables[\"p_Ïƒ_Î¼\"][t, sample_indices]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMSV_EMASO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SMSV_EMASOModel(BaseModel):\n",
    "    \"\"\"\n",
    "    SMSV_EMASO Model class.\n",
    "    \"\"\"\n",
    "    def __init__(self, observation, num_particles, time_steps, Ïƒ_Î¼=1.0):\n",
    "        super().__init__(observation, num_particles, time_steps)\n",
    "        # Parameter\n",
    "        self.Î±_Î¼_parameter = np.full(self.L, np.mean(observation[:24]))\n",
    "\n",
    "        # Variables\n",
    "        self.variables.update({\n",
    "            'Î¼':np.zeros((self.T, self.L)),\n",
    "            \"p_Î¼\":np.zeros((self.T, self.L)),\n",
    "            \"Î¼Ì„\":np.zeros((self.T, self.L)),\n",
    "            \"p_Î¼Ì„\":np.zeros((self.T, self.L)),\n",
    "            \"Ï•_Î¼\": np.zeros((self.T, self.L)),\n",
    "            \"p_Ï•_Î¼\":np.zeros((self.T, self.L)),\n",
    "            \"Ïƒ_Î¼\":np.zeros((self.T, self.L)),\n",
    "            \"p_Ïƒ_Î¼\":np.zeros((self.T, self.L)),\n",
    "            \"Î·\": np.zeros((self.T, self.L)),\n",
    "        })\n",
    "        print(self.variables[\"Ï•_Î¼\"])\n",
    "\n",
    "        # Initialization\n",
    "        self.variables[\"xÌ„\"][0] = self.U(-1, 5, self.L)\n",
    "        self.variables[\"Ï•_Î¼\"][0] = self.U(0, 1, self.L)\n",
    "        self.variables[\"Ï•_x\"][0] = 2 * self.B(20, 1.5, self.L) - 1\n",
    "        self.variables[\"Ïƒ_x\"][0] = self.U(0, 2, self.L)\n",
    "        \n",
    "        self.variables[\"Ïƒ_Î¼\"][0] = self.U(0, np.std(self.train), self.L)\n",
    "\n",
    "        self.variables[\"x\"][0] = self.N(\n",
    "            self.variables[\"xÌ„\"][0], \n",
    "            (self.variables[\"Ïƒ_x\"][0] ** 2) / (1 - self.variables[\"Ï•_x\"][0] ** 2)\n",
    "        )\n",
    "        self.variables[\"Î¼\"][0] = self.N(\n",
    "            self.Î±_Î¼_parameter, \n",
    "            (self.variables[\"Ïƒ_Î¼\"][0] ** 2) / (1 - self.variables[\"Ïƒ_Î¼\"][0] ** 2)\n",
    "        )   \n",
    "        self.variables[\"Ïµ\"][0] = self.N(0, 1, self.L)\n",
    "        self.variables[\"y\"][0] = self.observation_function(\n",
    "            self.variables[\"Î¼\"][0], self.variables[\"x\"][0], self.variables[\"Ïµ\"][0]\n",
    "        )\n",
    "    def Î¼_transition_function(y_t, Ï•_Î¼, Î¼_t):\n",
    "        particles = y_t + Ï•_Î¼ * (Î¼_t - y_t)\n",
    "        return particles\n",
    "\n",
    "    def particle_filtering(self):\n",
    "        \"\"\"\n",
    "        Particle filtering process for state estimation.\n",
    "        \"\"\"\n",
    "        for t in tqdm(range(1, self.T)):\n",
    "            # SOSS update for prior estimates\n",
    "            self.variables[\"p_xÌ„\"][t] = self.SOSS_update(self.Î±_shrink_factor, self.variables[\"xÌ„\"][t - 1])\n",
    "            self.variables[\"p_Ï•_x\"][t] = self.SOSS_update(self.Î±_shrink_factor, self.variables[\"Ï•_x\"][t - 1])\n",
    "            self.variables[\"p_Ïƒ_x\"][t] = self.SOSS_update(self.Î±_shrink_factor, self.variables[\"Ïƒ_x\"][t - 1])\n",
    "            self.variables[\"p_Ïƒ_Î¼\"][t] = self.SOSS_update(self.Î±_shrink_factor, self.variables[\"Ïƒ_Î¼\"][t - 1])\n",
    "            self.variables[\"p_Ï•_Î¼\"][t] = self.SOSS_update(self.Î±_shrink_factor, self.variables[\"Ï•_Î¼\"][t - 1])\n",
    "\n",
    "            # Generate system noise and calculate particles for x\n",
    "            self.variables[\"Î¾\"][t] = self.N(0, 1, self.L)\n",
    "            self.variables[\"p_x\"][t] = self.x_transition_function(\n",
    "                self.variables[\"p_xÌ„\"][t],\n",
    "                self.variables[\"p_Ï•_x\"][t],\n",
    "                self.variables[\"p_Ïƒ_x\"][t],\n",
    "                self.variables[\"Î¾\"][t],\n",
    "                self.variables[\"x\"][t - 1],\n",
    "            )\n",
    "\n",
    "            # Generate system noise and calculate particles for Î¼\n",
    "            self.variables[\"Î·\"][t] = self.N(0, 1, self.L)\n",
    "            self.variables[\"p_Î¼\"][t] = self.Î¼_transition_function(\n",
    "                self.observation[t - 1],\n",
    "                self.variables[\"p_Ï•_Î¼\"][t],\n",
    "                self.variables[\"p_Ïƒ_Î¼\"][t],\n",
    "                self.variables[\"Î·\"][t],\n",
    "                self.variables[\"Î¼\"][t - 1],\n",
    "            )\n",
    "\n",
    "            # Generate observation noise and calculate expected observations\n",
    "            self.variables[\"Ïµ\"][t] = self.N(0, 1, self.L)\n",
    "            self.variables[\"y\"][t] = self.observation_function(\n",
    "                self.variables[\"p_Î¼\"][t],\n",
    "                self.variables[\"p_x\"][t],\n",
    "                self.variables[\"Ïµ\"][t],\n",
    "            )\n",
    "\n",
    "            # Calculate likelihood using Gaussian observation likelihood\n",
    "            likelihood = self.observation_likelihood(self.observation[t], self.variables[\"p_Î¼\"][t], self.variables[\"p_x\"][t])\n",
    "            self.variables[\"Î±\"][t] = likelihood\n",
    "\n",
    "            # Normalize the likelihood to calculate weights\n",
    "            weights = self.variables[\"Î±\"][t]\n",
    "            weights /= np.sum(weights)\n",
    "\n",
    "            # Resample particles based on weights\n",
    "            cumulative_sum = np.cumsum(weights)\n",
    "            positions = (np.arange(self.L) + np.random.uniform(0, 1)) / self.L\n",
    "            sample_indices = np.searchsorted(cumulative_sum, positions)\n",
    "\n",
    "            # Resample all variables\n",
    "            self.variables[\"x\"][t] = self.variables[\"p_x\"][t, sample_indices]\n",
    "            self.variables[\"Î¼\"][t] = self.variables[\"p_Î¼\"][t, sample_indices]\n",
    "            self.variables[\"xÌ„\"][t] = self.variables[\"p_xÌ„\"][t, sample_indices]\n",
    "            self.variables[\"Ï•_x\"][t] = self.variables[\"p_Ï•_x\"][t, sample_indices]\n",
    "            self.variables[\"Ïƒ_x\"][t] = self.variables[\"p_Ïƒ_x\"][t, sample_indices]\n",
    "            self.variables[\"Ï•_Î¼\"][t] = self.variables[\"p_Ï•_Î¼\"][t, sample_indices]\n",
    "            self.variables[\"Ïƒ_Î¼\"][t] = self.variables[\"p_Ïƒ_Î¼\"][t, sample_indices]\n",
    "    \n",
    "    def plot(self):\n",
    "        \"\"\"\n",
    "        Plots the sequential estimations of parameters and expected returns.\n",
    "        \"\"\"\n",
    "        # Compute median, lower, and upper bounds for each parameter\n",
    "        xÌ„_median, xÌ„_lower, xÌ„_upper = self.compute_stats(self.variables[\"xÌ„\"])\n",
    "        Ï•_Î¼_median, Ï•_Î¼_lower, Ï•_Î¼_upper = self.compute_stats(self.variables[\"Ï•_Î¼\"])\n",
    "        Ï•_x_median, Ï•_x_lower, Ï•_x_upper = self.compute_stats(self.variables[\"Ï•_x\"])\n",
    "        Ïƒ_x_median, Ïƒ_x_lower, Ïƒ_x_upper = self.compute_stats(self.variables[\"Ïƒ_x\"])\n",
    "        Ïƒ_Î¼_median, Ïƒ_Î¼_lower, Ïƒ_Î¼_upper = self.compute_stats(self.variables[\"Ïƒ_Î¼\"])\n",
    "\n",
    "        # Set up plot style\n",
    "        sns.set_theme(style=\"whitegrid\")  # Use white grid style for better visualization\n",
    "        plt.rcParams[\"axes.grid\"] = True\n",
    "        plt.rcParams[\"axes.grid.axis\"] = \"y\"  # Enable horizontal grid lines only\n",
    "\n",
    "        # Create the figure and axes for a 3x2 grid of subplots\n",
    "        fig, axes = plt.subplots(3, 2, figsize=(12, 10))\n",
    "        dates = self.returns.index  # Dates for x-axis, assuming self.returns contains the returns DataFrame\n",
    "\n",
    "        # Sequential estimations of xÌ„\n",
    "        axes[0, 0].plot(dates, xÌ„_median, label=\"Median\", color=\"cornflowerblue\")\n",
    "        axes[0, 0].plot(dates, xÌ„_lower, linestyle=\"dotted\", color=\"orange\")\n",
    "        axes[0, 0].plot(dates, xÌ„_upper, linestyle=\"dotted\", color=\"orange\")\n",
    "        axes[0, 0].set_title(\"Sequential estimations of parameter $\\overline{x}$\")\n",
    "        axes[0, 0].set_ylim(-2, 6)\n",
    "\n",
    "        # Sequential estimations of Ï•_Î¼\n",
    "        axes[0, 1].plot(dates, Ï•_Î¼_median, label=\"Median\", color=\"cornflowerblue\")\n",
    "        axes[0, 1].plot(dates, Ï•_Î¼_lower, linestyle=\"dotted\", color=\"orange\")\n",
    "        axes[0, 1].plot(dates, Ï•_Î¼_upper, linestyle=\"dotted\", color=\"orange\")\n",
    "        axes[0, 1].set_title(\"Sequential estimations of parameter $\\phi_\\mu$\")\n",
    "        axes[0, 1].set_ylim(0, 1.2)\n",
    "\n",
    "        # Sequential estimations of Ï•_x\n",
    "        axes[1, 0].plot(dates, Ï•_x_median, label=\"Median\", color=\"cornflowerblue\")\n",
    "        axes[1, 0].plot(dates, Ï•_x_lower, linestyle=\"dotted\", color=\"orange\")\n",
    "        axes[1, 0].plot(dates, Ï•_x_upper, linestyle=\"dotted\", color=\"orange\")\n",
    "        axes[1, 0].set_title(\"Sequential estimations of parameter $\\phi_x$\")\n",
    "        axes[1, 0].set_ylim(0.4, 1.1)\n",
    "\n",
    "        # Sequential estimations of Ïƒ_Î¼\n",
    "        axes[1, 1].plot(dates, Ïƒ_Î¼_median, label=\"Median\", color=\"cornflowerblue\")\n",
    "        axes[1, 1].plot(dates, Ïƒ_Î¼_lower, linestyle=\"dotted\", color=\"orange\")\n",
    "        axes[1, 1].plot(dates, Ïƒ_Î¼_upper, linestyle=\"dotted\", color=\"orange\")\n",
    "        axes[1, 1].set_title(\"Sequential estimations of parameter $\\sigma_\\mu$\")\n",
    "        axes[1, 1].set_ylim(0, 4.5)\n",
    "\n",
    "        # Sequential estimations of Ïƒ_x\n",
    "        axes[2, 0].plot(dates, Ïƒ_x_median, label=\"Median\", color=\"cornflowerblue\")\n",
    "        axes[2, 0].plot(dates, Ïƒ_x_lower, linestyle=\"dotted\", color=\"orange\")\n",
    "        axes[2, 0].plot(dates, Ïƒ_x_upper, linestyle=\"dotted\", color=\"orange\")\n",
    "        axes[2, 0].set_title(\"Sequential estimations of parameter $\\sigma_x$\")\n",
    "        axes[2, 0].set_ylim(0, 2.5)\n",
    "\n",
    "        # Expected returns\n",
    "        observation = self.observation  # Assuming self.observation contains the observed returns\n",
    "        y_median = np.median(self.variables[\"y\"], axis=1)  # Median of expected returns\n",
    "        axes[2, 1].plot(dates[48:], observation[48:], linestyle=\"dotted\", color=\"grey\", label=\"Observed\")\n",
    "        axes[2, 1].plot(dates[48:], y_median[48:], color=\"orange\", label=\"Expected\")\n",
    "        axes[2, 1].set_title(\"Expected Returns\")\n",
    "        axes[2, 1].set_ylim(-20, 15)\n",
    "\n",
    "        # Add legends to the first subplot in each row\n",
    "        for i in range(3):\n",
    "            axes[i, 0].legend()\n",
    "\n",
    "        # Adjust layout for better appearance\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_name, observation, num_particles, time_steps, **kwargs):\n",
    "    \"\"\"\n",
    "    Factory function to get the appropriate model.\n",
    "    \"\"\"\n",
    "    models = {\n",
    "        \"CMSV\": CMSVModel(observation, num_particles, time_steps, **kwargs),\n",
    "        \"SMSV\": SMSVModel(observation, num_particles, time_steps, **kwargs),\n",
    "        \"SMSV+EMA\": SMSV_EMAModel(observation, num_particles, time_steps, **kwargs),\n",
    "        \"SMSV+EMASO\": SMSV_EMASOModel(observation, num_particles, time_steps, **kwargs),\n",
    "    }\n",
    "    if model_name not in models:\n",
    "        raise ValueError(f\"Model '{model_name}' is not recognized.\")\n",
    "    return models[model_name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Ï•_Î¼'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m     data \u001b[39m=\u001b[39m yf\u001b[39m.\u001b[39mdownload(ticker, start\u001b[39m=\u001b[39mstart_date, end\u001b[39m=\u001b[39mend_date, interval\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m1mo\u001b[39m\u001b[39m'\u001b[39m, progress\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)[\u001b[39m'\u001b[39m\u001b[39mAdj Close\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     13\u001b[0m     returns \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mpct_change()\u001b[39m.\u001b[39mdropna() \u001b[39m*\u001b[39m \u001b[39m100\u001b[39m  \u001b[39m# Calculate monthly returns\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m model \u001b[39m=\u001b[39m get_model(SMSV_EMASOModel, returns, num_particles \u001b[39m=\u001b[39;49m \u001b[39m1_000_000\u001b[39;49m, time_steps \u001b[39m=\u001b[39;49m \u001b[39m155\u001b[39;49m )\n",
      "Cell \u001b[0;32mIn[35], line 7\u001b[0m, in \u001b[0;36mget_model\u001b[0;34m(model_name, observation, num_particles, time_steps, **kwargs)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_model\u001b[39m(model_name, observation, num_particles, time_steps, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m      2\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m    Factory function to get the appropriate model.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     models \u001b[39m=\u001b[39m {\n\u001b[1;32m      6\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCMSV\u001b[39m\u001b[39m\"\u001b[39m: CMSVModel(observation, num_particles, time_steps, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs),\n\u001b[0;32m----> 7\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSMSV\u001b[39m\u001b[39m\"\u001b[39m: SMSVModel(observation, num_particles, time_steps, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs),\n\u001b[1;32m      8\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSMSV+EMA\u001b[39m\u001b[39m\"\u001b[39m: SMSV_EMAModel(observation, num_particles, time_steps, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs),\n\u001b[1;32m      9\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSMSV+EMASO\u001b[39m\u001b[39m\"\u001b[39m: SMSV_EMASOModel(observation, num_particles, time_steps, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs),\n\u001b[1;32m     10\u001b[0m     }\n\u001b[1;32m     11\u001b[0m     \u001b[39mif\u001b[39;00m model_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m models:\n\u001b[1;32m     12\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m is not recognized.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[20], line 24\u001b[0m, in \u001b[0;36mSMSVModel.__init__\u001b[0;34m(self, observation, num_particles, time_steps, Î²)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvariables[\u001b[39m\"\u001b[39m\u001b[39mÎ¼Ì„\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mU(\u001b[39m-\u001b[39m\u001b[39m5\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mL)\n\u001b[1;32m     23\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvariables[\u001b[39m\"\u001b[39m\u001b[39mxÌ„\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mU(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mL)\n\u001b[0;32m---> 24\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvariables[\u001b[39m\"\u001b[39;49m\u001b[39mÏ•_Î¼\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mU(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mL)\n\u001b[1;32m     25\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvariables[\u001b[39m\"\u001b[39m\u001b[39mÏƒ_Î¼\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mU(\u001b[39m0\u001b[39m, np\u001b[39m.\u001b[39mstd(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mL)\n\u001b[1;32m     26\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvariables[\u001b[39m\"\u001b[39m\u001b[39mÏ•_x\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mB(\u001b[39m20\u001b[39m, \u001b[39m1.5\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mL) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Ï•_Î¼'"
     ]
    }
   ],
   "source": [
    "tickers = [\n",
    "    \"^N225\",    # S&P 500 Index\n",
    "      # iShares U.S. Real Estate ETF (Morgan Stanley REIT Index)\n",
    "]\n",
    "\n",
    "# Download monthly returns data for the last 14 years\n",
    "start_date = \"2003-03-01\"\n",
    "end_date = \"2016-04-01\"\n",
    "\n",
    "# Fetch monthly data for each ticker\n",
    "for ticker in tickers:\n",
    "    data = yf.download(ticker, start=start_date, end=end_date, interval='1mo', progress=False)['Adj Close']\n",
    "    returns = data.pct_change().dropna() * 100  # Calculate monthly returns\n",
    "\n",
    "model = get_model(SMSV_EMASOModel, returns, num_particles = 1_000_000, time_steps = 155 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
