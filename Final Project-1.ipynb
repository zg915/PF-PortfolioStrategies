{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import uniform, beta, norm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import skew, kurtosis\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_descriptive_statistics(data):\n",
    "    \"\"\"\n",
    "    Calculate descriptive statistics for each column in the dataset.\n",
    "    \n",
    "    Parameters:\n",
    "        data (pd.DataFrame): DataFrame with numerical data for each index.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing Mean, Std. Dev., Skew, and Kurtosis.\n",
    "    \"\"\"\n",
    "    stats = {\n",
    "        \"Mean\": data.mean(),\n",
    "        \"Std. Dev.\": data.std(),\n",
    "        \"Skew\": data.apply(skew),\n",
    "        \"Kurtosis\": data.apply(lambda x: kurtosis(x, fisher=True))  # Fisher=True gives excess kurtosis\n",
    "    }\n",
    "    \n",
    "    return pd.DataFrame(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USE</th>\n",
       "      <th>USSC</th>\n",
       "      <th>UST</th>\n",
       "      <th>USB</th>\n",
       "      <th>LTB</th>\n",
       "      <th>BB</th>\n",
       "      <th>USR</th>\n",
       "      <th>GC</th>\n",
       "      <th>BC</th>\n",
       "      <th>TSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-12-01</th>\n",
       "      <td>0.408015</td>\n",
       "      <td>0.027108</td>\n",
       "      <td>-0.993055</td>\n",
       "      <td>1.812880</td>\n",
       "      <td>3.124899</td>\n",
       "      <td>0.468406</td>\n",
       "      <td>3.701063</td>\n",
       "      <td>-10.662434</td>\n",
       "      <td>-2.894356</td>\n",
       "      <td>0.405998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01</th>\n",
       "      <td>5.301067</td>\n",
       "      <td>7.668438</td>\n",
       "      <td>8.833362</td>\n",
       "      <td>1.239524</td>\n",
       "      <td>0.237975</td>\n",
       "      <td>1.602843</td>\n",
       "      <td>7.558280</td>\n",
       "      <td>11.395481</td>\n",
       "      <td>3.688525</td>\n",
       "      <td>5.667619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-01</th>\n",
       "      <td>4.340577</td>\n",
       "      <td>2.568956</td>\n",
       "      <td>6.410042</td>\n",
       "      <td>-1.277254</td>\n",
       "      <td>-2.829941</td>\n",
       "      <td>-0.202221</td>\n",
       "      <td>-1.150725</td>\n",
       "      <td>-2.964978</td>\n",
       "      <td>5.353938</td>\n",
       "      <td>4.218455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-01</th>\n",
       "      <td>2.766024</td>\n",
       "      <td>2.171514</td>\n",
       "      <td>4.874998</td>\n",
       "      <td>-1.573824</td>\n",
       "      <td>-4.224694</td>\n",
       "      <td>-0.497515</td>\n",
       "      <td>4.361363</td>\n",
       "      <td>-1.320834</td>\n",
       "      <td>-1.773539</td>\n",
       "      <td>2.627505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-04-01</th>\n",
       "      <td>-0.232274</td>\n",
       "      <td>-1.316574</td>\n",
       "      <td>-1.001722</td>\n",
       "      <td>2.499252</td>\n",
       "      <td>4.801574</td>\n",
       "      <td>1.003277</td>\n",
       "      <td>3.686116</td>\n",
       "      <td>-0.148032</td>\n",
       "      <td>-1.354158</td>\n",
       "      <td>-0.210375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-01</th>\n",
       "      <td>3.195099</td>\n",
       "      <td>-1.399620</td>\n",
       "      <td>6.301166</td>\n",
       "      <td>1.215946</td>\n",
       "      <td>1.825939</td>\n",
       "      <td>0.877783</td>\n",
       "      <td>0.624706</td>\n",
       "      <td>-0.134700</td>\n",
       "      <td>-0.171899</td>\n",
       "      <td>2.714648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-01</th>\n",
       "      <td>1.537427</td>\n",
       "      <td>10.643647</td>\n",
       "      <td>-1.521827</td>\n",
       "      <td>2.890084</td>\n",
       "      <td>3.654331</td>\n",
       "      <td>2.353104</td>\n",
       "      <td>9.281175</td>\n",
       "      <td>5.367196</td>\n",
       "      <td>-2.798104</td>\n",
       "      <td>2.252879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-01</th>\n",
       "      <td>2.336556</td>\n",
       "      <td>-1.688551</td>\n",
       "      <td>1.103867</td>\n",
       "      <td>1.349349</td>\n",
       "      <td>2.095666</td>\n",
       "      <td>1.453755</td>\n",
       "      <td>5.220651</td>\n",
       "      <td>2.092249</td>\n",
       "      <td>-2.081485</td>\n",
       "      <td>2.131556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-01</th>\n",
       "      <td>1.788252</td>\n",
       "      <td>0.368044</td>\n",
       "      <td>2.477588</td>\n",
       "      <td>1.386692</td>\n",
       "      <td>2.007479</td>\n",
       "      <td>1.317310</td>\n",
       "      <td>2.407239</td>\n",
       "      <td>5.088851</td>\n",
       "      <td>0.723654</td>\n",
       "      <td>1.717074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-01</th>\n",
       "      <td>-0.588365</td>\n",
       "      <td>-1.080598</td>\n",
       "      <td>-0.725319</td>\n",
       "      <td>-3.382326</td>\n",
       "      <td>-5.452729</td>\n",
       "      <td>-2.446154</td>\n",
       "      <td>-2.542702</td>\n",
       "      <td>4.299349</td>\n",
       "      <td>1.436909</td>\n",
       "      <td>-0.446041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 USE       USSC       UST       USB       LTB        BB  \\\n",
       "Date                                                                      \n",
       "2011-12-01  0.408015   0.027108 -0.993055  1.812880  3.124899  0.468406   \n",
       "2012-01-01  5.301067   7.668438  8.833362  1.239524  0.237975  1.602843   \n",
       "2012-02-01  4.340577   2.568956  6.410042 -1.277254 -2.829941 -0.202221   \n",
       "2012-03-01  2.766024   2.171514  4.874998 -1.573824 -4.224694 -0.497515   \n",
       "2012-04-01 -0.232274  -1.316574 -1.001722  2.499252  4.801574  1.003277   \n",
       "...              ...        ...       ...       ...       ...       ...   \n",
       "2024-06-01  3.195099  -1.399620  6.301166  1.215946  1.825939  0.877783   \n",
       "2024-07-01  1.537427  10.643647 -1.521827  2.890084  3.654331  2.353104   \n",
       "2024-08-01  2.336556  -1.688551  1.103867  1.349349  2.095666  1.453755   \n",
       "2024-09-01  1.788252   0.368044  2.477588  1.386692  2.007479  1.317310   \n",
       "2024-10-01 -0.588365  -1.080598 -0.725319 -3.382326 -5.452729 -2.446154   \n",
       "\n",
       "                 USR         GC        BC       TSE  \n",
       "Date                                                 \n",
       "2011-12-01  3.701063 -10.662434 -2.894356  0.405998  \n",
       "2012-01-01  7.558280  11.395481  3.688525  5.667619  \n",
       "2012-02-01 -1.150725  -2.964978  5.353938  4.218455  \n",
       "2012-03-01  4.361363  -1.320834 -1.773539  2.627505  \n",
       "2012-04-01  3.686116  -0.148032 -1.354158 -0.210375  \n",
       "...              ...        ...       ...       ...  \n",
       "2024-06-01  0.624706  -0.134700 -0.171899  2.714648  \n",
       "2024-07-01  9.281175   5.367196 -2.798104  2.252879  \n",
       "2024-08-01  5.220651   2.092249 -2.081485  2.131556  \n",
       "2024-09-01  2.407239   5.088851  0.723654  1.717074  \n",
       "2024-10-01 -2.542702   4.299349  1.436909 -0.446041  \n",
       "\n",
       "[155 rows x 10 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of yfinance-compatible tickers\n",
    "tickers = [\n",
    "    \"SPY\",      # S&P 500 ETF (large-cap U.S. equities)\n",
    "    \"IWM\",      # iShares Russell 2000 ETF (small-cap U.S. equities)\n",
    "    \"QQQ\",      # Nasdaq 100 ETF (tech-heavy U.S. equities)\n",
    "    \"IEF\",      # iShares 7-10 Year Treasury Bond ETF (intermediate bonds)\n",
    "    \"TLT\",      # iShares 20+ Year Treasury Bond ETF (long-term bonds)\n",
    "    \"BND\",      # Vanguard Total Bond Market ETF (broad bond market)\n",
    "    \"VNQ\",      # Vanguard Real Estate ETF (U.S. REITs)\n",
    "    \"GLD\",      # SPDR Gold Shares (gold commodity)\n",
    "    \"DBC\",      # Invesco DB Commodity Index Tracking Fund (broad commodities)\n",
    "    \"VTI\"       # Vanguard Total Stock Market ETF (overall U.S. equities)\n",
    "]\n",
    "\n",
    "# Download monthly returns data for the last 14 years\n",
    "start_date = \"2011-11-01\"\n",
    "end_date = \"2024-11-01\"\n",
    "\n",
    "# Fetch monthly data for each ticker\n",
    "monthly_returns = {}\n",
    "for ticker in tickers:\n",
    "    data = yf.download(ticker, start=start_date, end=end_date, interval='1mo', progress=False)['Adj Close']\n",
    "    returns = data.pct_change().dropna() * 100  # Calculate monthly returns\n",
    "    monthly_returns[ticker] = returns\n",
    "\n",
    "# Combine all into a single DataFrame\n",
    "monthly_returns_df = pd.DataFrame(monthly_returns)\n",
    "monthly_returns_df.index.name = \"Date\"\n",
    "\n",
    "# Abbreviation mapping for tickers\n",
    "abbreviation_mapping = {\n",
    "    \"SPY\": \"USE\",     # Large-cap U.S. equities\n",
    "    \"IWM\": \"USSC\",    # Small-cap U.S. equities\n",
    "    \"QQQ\": \"UST\",     # Technology-focused U.S. equities\n",
    "    \"IEF\": \"USB\",     # Intermediate-term U.S. bonds\n",
    "    \"TLT\": \"LTB\",     # Long-term U.S. bonds\n",
    "    \"BND\": \"BB\",      # Broad U.S. bond market\n",
    "    \"VNQ\": \"USR\",     # U.S. REITs\n",
    "    \"GLD\": \"GC\",      # Gold commodity\n",
    "    \"DBC\": \"BC\",      # Broad commodities\n",
    "    \"VTI\": \"TSE\"      # Total U.S. equities\n",
    "}\n",
    "\n",
    "# Rename columns based on the abbreviation mapping\n",
    "monthly_returns_df.rename(columns=abbreviation_mapping, inplace=True)\n",
    "monthly_returns_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std. Dev.</th>\n",
       "      <th>Skew</th>\n",
       "      <th>Kurtosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>USE</th>\n",
       "      <td>1.223233</td>\n",
       "      <td>4.144438</td>\n",
       "      <td>-0.444681</td>\n",
       "      <td>0.978387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USSC</th>\n",
       "      <td>0.971101</td>\n",
       "      <td>5.501756</td>\n",
       "      <td>-0.333031</td>\n",
       "      <td>1.637728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UST</th>\n",
       "      <td>1.598465</td>\n",
       "      <td>5.009285</td>\n",
       "      <td>-0.273878</td>\n",
       "      <td>0.221404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USB</th>\n",
       "      <td>0.117529</td>\n",
       "      <td>1.868574</td>\n",
       "      <td>0.037401</td>\n",
       "      <td>0.112869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LTB</th>\n",
       "      <td>0.131238</td>\n",
       "      <td>3.904732</td>\n",
       "      <td>0.319343</td>\n",
       "      <td>0.167585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BB</th>\n",
       "      <td>0.152360</td>\n",
       "      <td>1.392525</td>\n",
       "      <td>-0.028788</td>\n",
       "      <td>1.141847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USR</th>\n",
       "      <td>0.800214</td>\n",
       "      <td>5.064624</td>\n",
       "      <td>-0.412084</td>\n",
       "      <td>1.282603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GC</th>\n",
       "      <td>0.351601</td>\n",
       "      <td>4.363482</td>\n",
       "      <td>0.188758</td>\n",
       "      <td>-0.083944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BC</th>\n",
       "      <td>0.039117</td>\n",
       "      <td>4.790997</td>\n",
       "      <td>-0.398904</td>\n",
       "      <td>0.449247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSE</th>\n",
       "      <td>1.201381</td>\n",
       "      <td>4.253102</td>\n",
       "      <td>-0.459499</td>\n",
       "      <td>1.213139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Mean  Std. Dev.      Skew  Kurtosis\n",
       "USE   1.223233   4.144438 -0.444681  0.978387\n",
       "USSC  0.971101   5.501756 -0.333031  1.637728\n",
       "UST   1.598465   5.009285 -0.273878  0.221404\n",
       "USB   0.117529   1.868574  0.037401  0.112869\n",
       "LTB   0.131238   3.904732  0.319343  0.167585\n",
       "BB    0.152360   1.392525 -0.028788  1.141847\n",
       "USR   0.800214   5.064624 -0.412084  1.282603\n",
       "GC    0.351601   4.363482  0.188758 -0.083944\n",
       "BC    0.039117   4.790997 -0.398904  0.449247\n",
       "TSE   1.201381   4.253102 -0.459499  1.213139"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate Descriptive Statistics\n",
    "descriptive_stats = calculate_descriptive_statistics(monthly_returns_df)\n",
    "descriptive_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USE</th>\n",
       "      <th>USSC</th>\n",
       "      <th>UST</th>\n",
       "      <th>USB</th>\n",
       "      <th>LTB</th>\n",
       "      <th>BB</th>\n",
       "      <th>USR</th>\n",
       "      <th>GC</th>\n",
       "      <th>BC</th>\n",
       "      <th>TSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.223233</td>\n",
       "      <td>0.971101</td>\n",
       "      <td>1.598465</td>\n",
       "      <td>0.117529</td>\n",
       "      <td>0.131238</td>\n",
       "      <td>0.152360</td>\n",
       "      <td>0.800214</td>\n",
       "      <td>0.351601</td>\n",
       "      <td>0.039117</td>\n",
       "      <td>1.201381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.144438</td>\n",
       "      <td>5.501756</td>\n",
       "      <td>5.009285</td>\n",
       "      <td>1.868574</td>\n",
       "      <td>3.904732</td>\n",
       "      <td>1.392525</td>\n",
       "      <td>5.064624</td>\n",
       "      <td>4.363482</td>\n",
       "      <td>4.790997</td>\n",
       "      <td>4.253102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-12.998732</td>\n",
       "      <td>-21.779559</td>\n",
       "      <td>-13.488935</td>\n",
       "      <td>-4.737245</td>\n",
       "      <td>-9.442612</td>\n",
       "      <td>-4.192765</td>\n",
       "      <td>-20.016045</td>\n",
       "      <td>-11.058839</td>\n",
       "      <td>-17.340184</td>\n",
       "      <td>-14.311355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.802328</td>\n",
       "      <td>-1.986510</td>\n",
       "      <td>-1.502412</td>\n",
       "      <td>-1.020461</td>\n",
       "      <td>-2.557437</td>\n",
       "      <td>-0.549809</td>\n",
       "      <td>-2.524590</td>\n",
       "      <td>-2.507565</td>\n",
       "      <td>-2.981861</td>\n",
       "      <td>-0.945027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.701163</td>\n",
       "      <td>1.214503</td>\n",
       "      <td>1.996835</td>\n",
       "      <td>0.031522</td>\n",
       "      <td>-0.035009</td>\n",
       "      <td>0.112023</td>\n",
       "      <td>1.127501</td>\n",
       "      <td>-0.167167</td>\n",
       "      <td>-0.038801</td>\n",
       "      <td>1.734416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.479714</td>\n",
       "      <td>4.215610</td>\n",
       "      <td>4.816796</td>\n",
       "      <td>1.218858</td>\n",
       "      <td>2.267531</td>\n",
       "      <td>0.868345</td>\n",
       "      <td>3.693589</td>\n",
       "      <td>2.960073</td>\n",
       "      <td>3.455202</td>\n",
       "      <td>3.498233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13.361051</td>\n",
       "      <td>18.244171</td>\n",
       "      <td>15.218765</td>\n",
       "      <td>4.634434</td>\n",
       "      <td>11.045844</td>\n",
       "      <td>4.519331</td>\n",
       "      <td>13.191192</td>\n",
       "      <td>11.395481</td>\n",
       "      <td>10.197628</td>\n",
       "      <td>13.695173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              USE        USSC         UST         USB         LTB          BB  \\\n",
       "count  155.000000  155.000000  155.000000  155.000000  155.000000  155.000000   \n",
       "mean     1.223233    0.971101    1.598465    0.117529    0.131238    0.152360   \n",
       "std      4.144438    5.501756    5.009285    1.868574    3.904732    1.392525   \n",
       "min    -12.998732  -21.779559  -13.488935   -4.737245   -9.442612   -4.192765   \n",
       "25%     -0.802328   -1.986510   -1.502412   -1.020461   -2.557437   -0.549809   \n",
       "50%      1.701163    1.214503    1.996835    0.031522   -0.035009    0.112023   \n",
       "75%      3.479714    4.215610    4.816796    1.218858    2.267531    0.868345   \n",
       "max     13.361051   18.244171   15.218765    4.634434   11.045844    4.519331   \n",
       "\n",
       "              USR          GC          BC         TSE  \n",
       "count  155.000000  155.000000  155.000000  155.000000  \n",
       "mean     0.800214    0.351601    0.039117    1.201381  \n",
       "std      5.064624    4.363482    4.790997    4.253102  \n",
       "min    -20.016045  -11.058839  -17.340184  -14.311355  \n",
       "25%     -2.524590   -2.507565   -2.981861   -0.945027  \n",
       "50%      1.127501   -0.167167   -0.038801    1.734416  \n",
       "75%      3.693589    2.960073    3.455202    3.498233  \n",
       "max     13.191192   11.395481   10.197628   13.695173  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly_returns_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USE</th>\n",
       "      <th>USSC</th>\n",
       "      <th>UST</th>\n",
       "      <th>USB</th>\n",
       "      <th>LTB</th>\n",
       "      <th>BB</th>\n",
       "      <th>USR</th>\n",
       "      <th>GC</th>\n",
       "      <th>BC</th>\n",
       "      <th>TSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.223233</td>\n",
       "      <td>0.971101</td>\n",
       "      <td>1.598465</td>\n",
       "      <td>0.117529</td>\n",
       "      <td>0.131238</td>\n",
       "      <td>0.152360</td>\n",
       "      <td>0.800214</td>\n",
       "      <td>0.351601</td>\n",
       "      <td>0.039117</td>\n",
       "      <td>1.201381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.144438</td>\n",
       "      <td>5.501756</td>\n",
       "      <td>5.009285</td>\n",
       "      <td>1.868574</td>\n",
       "      <td>3.904732</td>\n",
       "      <td>1.392525</td>\n",
       "      <td>5.064624</td>\n",
       "      <td>4.363482</td>\n",
       "      <td>4.790997</td>\n",
       "      <td>4.253102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-12.998732</td>\n",
       "      <td>-21.779559</td>\n",
       "      <td>-13.488935</td>\n",
       "      <td>-4.737245</td>\n",
       "      <td>-9.442612</td>\n",
       "      <td>-4.192765</td>\n",
       "      <td>-20.016045</td>\n",
       "      <td>-11.058839</td>\n",
       "      <td>-17.340184</td>\n",
       "      <td>-14.311355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.802328</td>\n",
       "      <td>-1.986510</td>\n",
       "      <td>-1.502412</td>\n",
       "      <td>-1.020461</td>\n",
       "      <td>-2.557437</td>\n",
       "      <td>-0.549809</td>\n",
       "      <td>-2.524590</td>\n",
       "      <td>-2.507565</td>\n",
       "      <td>-2.981861</td>\n",
       "      <td>-0.945027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.701163</td>\n",
       "      <td>1.214503</td>\n",
       "      <td>1.996835</td>\n",
       "      <td>0.031522</td>\n",
       "      <td>-0.035009</td>\n",
       "      <td>0.112023</td>\n",
       "      <td>1.127501</td>\n",
       "      <td>-0.167167</td>\n",
       "      <td>-0.038801</td>\n",
       "      <td>1.734416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.479714</td>\n",
       "      <td>4.215610</td>\n",
       "      <td>4.816796</td>\n",
       "      <td>1.218858</td>\n",
       "      <td>2.267531</td>\n",
       "      <td>0.868345</td>\n",
       "      <td>3.693589</td>\n",
       "      <td>2.960073</td>\n",
       "      <td>3.455202</td>\n",
       "      <td>3.498233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13.361051</td>\n",
       "      <td>18.244171</td>\n",
       "      <td>15.218765</td>\n",
       "      <td>4.634434</td>\n",
       "      <td>11.045844</td>\n",
       "      <td>4.519331</td>\n",
       "      <td>13.191192</td>\n",
       "      <td>11.395481</td>\n",
       "      <td>10.197628</td>\n",
       "      <td>13.695173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              USE        USSC         UST         USB         LTB          BB  \\\n",
       "count  155.000000  155.000000  155.000000  155.000000  155.000000  155.000000   \n",
       "mean     1.223233    0.971101    1.598465    0.117529    0.131238    0.152360   \n",
       "std      4.144438    5.501756    5.009285    1.868574    3.904732    1.392525   \n",
       "min    -12.998732  -21.779559  -13.488935   -4.737245   -9.442612   -4.192765   \n",
       "25%     -0.802328   -1.986510   -1.502412   -1.020461   -2.557437   -0.549809   \n",
       "50%      1.701163    1.214503    1.996835    0.031522   -0.035009    0.112023   \n",
       "75%      3.479714    4.215610    4.816796    1.218858    2.267531    0.868345   \n",
       "max     13.361051   18.244171   15.218765    4.634434   11.045844    4.519331   \n",
       "\n",
       "              USR          GC          BC         TSE  \n",
       "count  155.000000  155.000000  155.000000  155.000000  \n",
       "mean     0.800214    0.351601    0.039117    1.201381  \n",
       "std      5.064624    4.363482    4.790997    4.253102  \n",
       "min    -20.016045  -11.058839  -17.340184  -14.311355  \n",
       "25%     -2.524590   -2.507565   -2.981861   -0.945027  \n",
       "50%      1.127501   -0.167167   -0.038801    1.734416  \n",
       "75%      3.693589    2.960073    3.455202    3.498233  \n",
       "max     13.191192   11.395481   10.197628   13.695173  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly_returns_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel:\n",
    "    \"\"\"\n",
    "    Base class for all models, providing shared functionality, variables, parameters, and methods.\n",
    "    \"\"\"\n",
    "    def __init__(self, observation, num_particles = 1_000_000, time_steps = 155):\n",
    "        \"\"\"Initialize base model parameters, variables, and shared functions.\"\"\"\n",
    "        self.observation = observation.values  # Y = returns.values\n",
    "        self.L = num_particles  # Number of particles\n",
    "        self.T = time_steps  # Number of time steps\n",
    "        self.δ = 0.98\n",
    "        self.α_shrink_factor = (3 * self.δ - 1) / (2 * self.δ)\n",
    "        self.train = self.observation[:48]\n",
    "\n",
    "        # Common variables\n",
    "        self.variables = {\n",
    "            \"x\": np.zeros((self.T, self.L)),  # Latent x\n",
    "            \"p_x\": np.zeros((self.T, self.L)), # particles of latent x, shape (T, L)\n",
    "            \"x̄\": np.zeros((self.T, self.L)),\n",
    "            \"p_x̄\":np.zeros((self.T, self.L)),\n",
    "            \"ϕ_x\":np.zeros((self.T, self.L)),\n",
    "            \"p_ϕ_x\":np.zeros((self.T, self.L)),\n",
    "            \"σ_x\": np.zeros((self.T, self.L)),\n",
    "            \"p_σ_x\":np.zeros((self.T, self.L)),\n",
    "\n",
    "            \"α\":np.zeros((self.T, self.L)),\n",
    "            \"y\": np.zeros((self.T, self.L)),  # Estimated return\n",
    "            \"ξ\": np.zeros((self.T, self.L)),\n",
    "            \"ϵ\":np.zeros((self.T, self.L)),\n",
    "        }\n",
    "            \n",
    "    @staticmethod\n",
    "    def N(mean, variance, size=None):\n",
    "        \"\"\"Generate samples from a normal distribution.\"\"\"\n",
    "        return np.random.normal(mean, np.sqrt(variance), size)\n",
    "\n",
    "    @staticmethod\n",
    "    def U(start_point, end_point, size=None):\n",
    "        \"\"\"Generate samples from a uniform distribution.\"\"\"\n",
    "        return np.random.uniform(start_point, end_point, size)\n",
    "\n",
    "    @staticmethod\n",
    "    def B(α, β, size=None):\n",
    "        \"\"\"Generate samples from a beta distribution.\"\"\"\n",
    "        return np.random.beta(α, β, size)\n",
    "\n",
    "    @staticmethod\n",
    "    def SOSS_update(α, θ):\n",
    "        \"\"\"Perform second-order stochastic smoothing.\"\"\"\n",
    "        return BaseModel.N(α * θ + (1 - α) * np.mean(θ), (1 - α**2) * np.var(θ))\n",
    "\n",
    "    @staticmethod\n",
    "    def x_transition_function(x̄, ϕ_x, σ_x, ξ_t, x_t):\n",
    "        \"\"\"Transition function for variable x.\"\"\"\n",
    "        return x̄ + ϕ_x * (x_t - x̄) + σ_x * ξ_t\n",
    "\n",
    "    @staticmethod\n",
    "    def observation_function(μ_t, x_t, ϵ_t):\n",
    "        \"\"\"Observation function.\"\"\"\n",
    "        return μ_t + np.exp(x_t / 2) * ϵ_t\n",
    "\n",
    "    @staticmethod\n",
    "    def observation_likelihood(y, μ, x):\n",
    "        \"\"\"Calculate the observation likelihood.\"\"\"\n",
    "        σ_t = np.exp(x / 2)\n",
    "        return (1 / (np.sqrt(2 * np.pi) * σ_t)) * np.exp(-((y - μ) ** 2) / (2 * σ_t**2))\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_stats(data):\n",
    "        median = np.median(data, axis=1)\n",
    "        lower_percentile = np.percentile(data, 2.5, axis=1)\n",
    "        upper_percentile = np.percentile(data, 97.5, axis=1)\n",
    "        return median, lower_percentile, upper_percentile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CMSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CMSVModel(BaseModel):\n",
    "    \"\"\"\n",
    "    CMSV Model class.\n",
    "    \"\"\"\n",
    "    def __init__(self, observation, num_particles, time_steps, β=0.8):\n",
    "        super().__init__(observation, num_particles, time_steps)\n",
    "        # Variables\n",
    "        self.variables.update({\n",
    "            \"μ̄\":np.zeros((self.T, self.L)),\n",
    "            \"p_μ̄\":np.zeros((self.T, self.L)),\n",
    "        })\n",
    "\n",
    "        # Initialization\n",
    "        self.variables[\"μ̄\"][0] = self.U(-5, 5, self.L)\n",
    "        self.variables[\"x̄\"][0] = self.U(-1, 5, self.L)\n",
    "        self.variables[\"ϕ_x\"][0] = 2 * self.B(20, 1.5, self.L) - 1\n",
    "        self.variables[\"σ_x\"][0] = self.U(0, 2, self.L)\n",
    "        \n",
    "        self.variables[\"x\"][0] = self.N(\n",
    "            self.variables[\"x̄\"][0], \n",
    "            (self.variables[\"σ_x\"][0] ** 2) / (1 - self.variables[\"ϕ_x\"][0] ** 2)\n",
    "        )\n",
    "        self.variables[\"ϵ\"][0] = self.N(0, 1, self.L)\n",
    "        self.variables[\"y\"][0] = self.observation_function(\n",
    "            self.variables[\"μ̄\"][0], self.variables[\"x\"][0], self.variables[\"ϵ\"][0]\n",
    "        )\n",
    "\n",
    "    def particle_filtering(self):\n",
    "        \"\"\"Particle filtering process for state estimation.\"\"\"\n",
    "        for t in tqdm(range(1, self.T)):\n",
    "            # SOSS update for prior estimates\n",
    "            self.variables[\"p_x̄\"][t] = self.SOSS_update(self.α_shrink_factor, self.variables[\"x̄\"][t - 1])\n",
    "            self.variables[\"p_ϕ_x\"][t] = self.SOSS_update(self.α_shrink_factor, self.variables[\"ϕ_x\"][t - 1])\n",
    "            self.variables[\"p_σ_x\"][t] = self.SOSS_update(self.α_shrink_factor, self.variables[\"σ_x\"][t - 1])\n",
    "            self.variables[\"p_μ̄\"][t] = self.SOSS_update(self.α_shrink_factor, self.variables[\"μ̄\"][t - 1])\n",
    "\n",
    "            # Generate system noise and calculate particles for x\n",
    "            self.variables[\"ξ\"][t] = self.N(0, 1, self.L)\n",
    "            self.variables[\"p_x\"][t] = self.x_transition_function(\n",
    "                self.variables[\"p_x̄\"][t],\n",
    "                self.variables[\"p_ϕ_x\"][t],\n",
    "                self.variables[\"p_σ_x\"][t],\n",
    "                self.variables[\"ξ\"][t],\n",
    "                self.variables[\"x\"][t - 1],\n",
    "            )\n",
    "\n",
    "            # Generate observation noise and calculate expected observations\n",
    "            self.variables[\"ϵ\"][t] = self.N(0, 1, self.L)\n",
    "            self.variables[\"y\"][t] = self.observation_function(\n",
    "                self.variables[\"p_μ̄\"][t], self.variables[\"p_x\"][t], self.variables[\"ϵ\"][t]\n",
    "            )\n",
    "\n",
    "            # Calculate likelihood using Gaussian observation likelihood\n",
    "            self.variables[\"α\"][t] = self.observation_likelihood(self.observation[t], self.variables[\"p_μ̄\"][t], self.variables[\"p_x\"][t])\n",
    "\n",
    "            # Normalize the likelihood to calculate weights\n",
    "            weights = self.variables[\"α\"][t]\n",
    "            weights /= np.sum(self.variables[\"α\"][t])\n",
    "\n",
    "            # Resample particles based on weights\n",
    "            cumulative_sum = np.cumsum(weights)\n",
    "            positions = (np.arange(self.L) + np.random.uniform(0, 1)) / self.L\n",
    "            sample_indices = np.searchsorted(cumulative_sum, positions)\n",
    "\n",
    "            # Resample all variables\n",
    "            self.variables[\"x\"][t] = self.variables[\"p_x\"][t, sample_indices]\n",
    "            self.variables[\"x̄\"][t] = self.variables[\"p_x̄\"][t, sample_indices]\n",
    "            self.variables[\"μ̄\"][t] = self.variables[\"p_μ̄\"][t, sample_indices]\n",
    "            self.variables[\"ϕ_x\"][t] = self.variables[\"p_ϕ_x\"][t, sample_indices]\n",
    "            self.variables[\"σ_x\"][t] = self.variables[\"p_σ_x\"][t, sample_indices]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SMSVModel(BaseModel):\n",
    "    \"\"\"\n",
    "    SMSV Model class.\n",
    "    \"\"\"\n",
    "    def __init__(self, observation, num_particles, time_steps, β=0.8):\n",
    "        super().__init__(observation, num_particles, time_steps)\n",
    "\n",
    "        # Variables\n",
    "        self.variables.update({\n",
    "            'μ':np.zeros((self.T, self.L)),\n",
    "            \"p_μ\":np.zeros((self.T, self.L)),\n",
    "            \"μ̄\":np.zeros((self.T, self.L)),\n",
    "            \"p_μ̄\":np.zeros((self.T, self.L)),\n",
    "            \"σ_μ\": np.zeros((self.T, self.L)),\n",
    "            \"p_ϕ_μ\":np.zeros((self.T, self.L)),\n",
    "            \"σ_μ\":np.zeros((self.T, self.L)),\n",
    "            \"p_σ_μ\":np.zeros((self.T, self.L)),\n",
    "            \"η\": np.zeros((self.T, self.L)),\n",
    "        })\n",
    "\n",
    "        # Initialization\n",
    "        self.variables[\"μ̄\"][0] = self.U(-5, 5, self.L)\n",
    "        self.variables[\"x̄\"][0] = self.U(-1, 5, self.L)\n",
    "        self.variables[\"ϕ_μ\"][0] = self.U(0, 1, self.L)\n",
    "        self.variables[\"σ_μ\"][0] = self.U(0, np.std(self.train), self.L)\n",
    "        self.variables[\"ϕ_x\"][0] = 2 * self.B(20, 1.5, self.L) - 1\n",
    "        self.variables[\"σ_x\"][0] = self.U(0, 2, self.L)\n",
    "        self.variables[\"x\"][0] = self.N(\n",
    "            self.variables[\"x̄\"][0], \n",
    "            (self.variables[\"σ_x\"][0] ** 2) / (1 - self.variables[\"ϕ_x\"][0] ** 2)\n",
    "        )\n",
    "        self.variables[\"μ\"][0] = self.N(\n",
    "            self.variables[\"μ̄\"][0], \n",
    "            (self.variables[\"σ_μ\"][0] ** 2) / (1 - self.variables[\"σ_μ\"][0] ** 2)\n",
    "        )        \n",
    "        \n",
    "        self.variables[\"ϵ\"][0] = self.N(0, 1, self.L)\n",
    "        self.variables[\"y\"][0] = self.observation_function(\n",
    "            self.variables[\"μ\"][0], self.variables[\"x\"][0], self.variables[\"ϵ\"][0]\n",
    "        )\n",
    "\n",
    "    # functions\n",
    "    def μ_transition_function(μ̄, ϕ_μ, σ_μ, η_μ, μ_t):\n",
    "        particles = μ̄ + \n",
    "        * (μ_t - μ̄) + σ_μ * η_μ\n",
    "        return particles\n",
    "\n",
    "    def particle_filtering(self):\n",
    "        \"\"\"Particle filtering process for state estimation.\"\"\"\n",
    "        for t in tqdm(range(1, self.T)):\n",
    "            # SOSS update for prior estimates\n",
    "            self.variables[\"p_x̄\"][t] = self.SOSS_update(self.α_shrink_factor, self.variables[\"x̄\"][t - 1])\n",
    "            self.variables[\"p_ϕ_x\"][t] = self.SOSS_update(self.α_shrink_factor, self.variables[\"ϕ_x\"][t - 1])\n",
    "            self.variables[\"p_σ_x\"][t] = self.SOSS_update(self.α_shrink_factor, self.variables[\"σ_x\"][t - 1])\n",
    "            self.variables[\"p_μ̄\"][t] = self.SOSS_update(self.α_shrink_factor, self.variables[\"μ̄\"][t - 1])\n",
    "            self.variables[\"p_σ_μ\"][t] = self.SOSS_update(self.α_shrink_factor, self.variables[\"σ_μ\"][t - 1])\n",
    "            self.variables[\"p_ϕ_μ\"][t] = self.SOSS_update(self.α_shrink_factor, self.variables[\"ϕ_μ\"][t - 1])\n",
    "\n",
    "            # Generate system noise and calculate particles for x\n",
    "            self.variables[\"ξ\"][t] = self.N(0, 1, self.L)\n",
    "            self.variables[\"p_x\"][t] = self.x_transition_function(\n",
    "                self.variables[\"p_x̄\"][t],\n",
    "                self.variables[\"p_ϕ_x\"][t],\n",
    "                self.variables[\"p_σ_x\"][t],\n",
    "                self.variables[\"ξ\"][t],\n",
    "                self.variables[\"x\"][t - 1],\n",
    "            )\n",
    "\n",
    "            # Generate system noise and calculate particles for μ\n",
    "            self.variables[\"η\"][t] = self.N(0, 1, self.L)\n",
    "            self.variables[\"p_μ\"][t] = self.μ_transition_function(\n",
    "                self.variables[\"p_μ̄\"][t],\n",
    "                self.variables[\"p_ϕ_μ\"][t],\n",
    "                self.variables[\"p_σ_μ\"][t],\n",
    "                self.variables[\"η\"][t],\n",
    "                self.variables[\"μ\"][t - 1],\n",
    "            )\n",
    "\n",
    "            # Generate observation noise and calculate expected observations\n",
    "            self.variables[\"ϵ\"][t] = self.N(0, 1, self.L)\n",
    "            self.variables[\"y\"][t] = self.observation_function(\n",
    "                self.variables[\"p_μ\"][t], self.variables[\"p_x\"][t], self.variables[\"ϵ\"][t]\n",
    "            )\n",
    "\n",
    "            # Calculate likelihood using Gaussian observation likelihood\n",
    "            likelihood = self.observation_likelihood(self.observation[t], self.variables[\"p_μ\"][t], self.variables[\"p_x\"][t])\n",
    "            self.variables[\"α\"][t] = likelihood\n",
    "\n",
    "            # Normalize the likelihood to calculate weights\n",
    "            weights = self.variables[\"α\"][t]\n",
    "            weights /= np.sum(weights)\n",
    "\n",
    "            # Resample particles based on weights\n",
    "            cumulative_sum = np.cumsum(weights)\n",
    "            positions = (np.arange(self.L) + np.random.uniform(0, 1)) / self.L\n",
    "            sample_indices = np.searchsorted(cumulative_sum, positions)\n",
    "\n",
    "            # Resample all variables\n",
    "            self.variables[\"x\"][t] = self.variables[\"p_x\"][t, sample_indices]\n",
    "            self.variables[\"μ\"][t] = self.variables[\"p_μ\"][t, sample_indices]\n",
    "            self.variables[\"x̄\"][t] = self.variables[\"p_x̄\"][t, sample_indices]\n",
    "            self.variables[\"μ̄\"][t] = self.variables[\"p_μ̄\"][t, sample_indices]\n",
    "            self.variables[\"ϕ_x\"][t] = self.variables[\"p_ϕ_x\"][t, sample_indices]\n",
    "            self.variables[\"σ_x\"][t] = self.variables[\"p_σ_x\"][t, sample_indices]\n",
    "            self.variables[\"ϕ_μ\"][t] = self.variables[\"p_ϕ_μ\"][t, sample_indices]\n",
    "            self.variables[\"σ_μ\"][t] = self.variables[\"p_σ_μ\"][t, sample_indices]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMSV_EMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SMSV_EMAModel(BaseModel):\n",
    "    \"\"\"\n",
    "    SMSV_EMA Model class.\n",
    "    \"\"\"\n",
    "    def __init__(self, observation, num_particles, time_steps, β=0.8):\n",
    "        super().__init__(observation, num_particles, time_steps)\n",
    "        # Parameter\n",
    "        self.α_μ_parameter = np.full(self.L, np.mean(observation[:24]))\n",
    "        self.ϕ_μ = np.full(self.L, 1 - self.β)# shape (L, 1)\n",
    "        self.σ_μ = self.U(0, self.calculate_σ_μ(self.α_μ_parameter, self.observation, self.β), self.L)\n",
    "        \n",
    "        # Initialization\n",
    "        self.variables[\"x̄\"][0] = self.U(-1, 5, self.L)\n",
    "        self.variables[\"ϕ_x\"][0] = 2 * self.B(20, 1.5, self.L) - 1\n",
    "        self.variables[\"σ_x\"][0] = self.U(0, 2, self.L)\n",
    "        \n",
    "        self.variables[\"x\"][0] = self.N(\n",
    "            self.variables[\"x̄\"][0], \n",
    "            (self.variables[\"σ_x\"][0] ** 2) / (1 - self.variables[\"ϕ_x\"][0] ** 2)\n",
    "        )\n",
    "        self.variables[\"μ\"][0] = self.N(\n",
    "            self.α_μ_parameter, \n",
    "            (self.variables[\"σ_μ\"][0] ** 2) / (1 - self.variables[\"σ_μ\"][0] ** 2)\n",
    "        )   \n",
    "        self.variables[\"ϵ\"][0] = self.N(0, 1, self.L)\n",
    "        self.variables[\"y\"][0] = self.observation_function(\n",
    "            self.variables[\"μ\"][0], self.variables[\"x\"][0], self.variables[\"ϵ\"][0]\n",
    "        )\n",
    "\n",
    "    def μ_transition_function(y_t, ϕ_μ, μ_t):\n",
    "        particles = y_t + ϕ_μ * (μ_t - y_t)\n",
    "        return particles\n",
    "    \n",
    "    def calculate_σ_μ(α, Y, β):\n",
    "        μ̄ = np.zeros(len(Y))\n",
    "        μ̄[0] = α[0]\n",
    "        for i in range(1, len(Y)):\n",
    "            μ̄[i] = β * Y[i - 1] + (1 - β) * μ̄[i - 1]\n",
    "        return np.std(μ̄)\n",
    "    def particle_filtering(self):\n",
    "        \"\"\"Particle filtering process for state estimation.\"\"\"\n",
    "        for t in tqdm(range(1, self.T)):\n",
    "            # SOSS update for prior estimates\n",
    "            self.variables[\"p_x̄\"][t] = self.SOSS_update(self.α_shrink_factor, self.variables[\"x̄\"][t - 1])\n",
    "            self.variables[\"p_ϕ_x\"][t] = self.SOSS_update(self.α_shrink_factor, self.variables[\"ϕ_x\"][t - 1])\n",
    "            self.variables[\"p_σ_x\"][t] = self.SOSS_update(self.α_shrink_factor, self.variables[\"σ_x\"][t - 1])\n",
    "            self.variables[\"p_μ̄\"][t] = self.SOSS_update(self.α_shrink_factor, self.variables[\"μ̄\"][t - 1])\n",
    "            self.variables[\"p_σ_μ\"][t] = self.SOSS_update(self.α_shrink_factor, self.variables[\"σ_μ\"][t - 1])\n",
    "            self.variables[\"p_ϕ_μ\"][t] = self.SOSS_update(self.α_shrink_factor, self.variables[\"ϕ_μ\"][t - 1])\n",
    "\n",
    "            # Generate system noise and calculate particles for x\n",
    "            self.variables[\"ξ\"][t] = self.N(0, 1, self.L)\n",
    "            self.variables[\"p_x\"][t] = self.x_transition_function(\n",
    "                self.variables[\"p_x̄\"][t],\n",
    "                self.variables[\"p_ϕ_x\"][t],\n",
    "                self.variables[\"p_σ_x\"][t],\n",
    "                self.variables[\"ξ\"][t],\n",
    "                self.variables[\"x\"][t - 1],\n",
    "            )\n",
    "\n",
    "            # Generate system noise and calculate particles for μ\n",
    "            self.variables[\"η\"][t] = self.N(0, 1, self.L)\n",
    "            self.variables[\"p_μ\"][t] = self.μ_transition_function(\n",
    "                self.variables[\"p_μ̄\"][t],\n",
    "                self.variables[\"p_ϕ_μ\"][t],\n",
    "                self.variables[\"p_σ_μ\"][t],\n",
    "                self.variables[\"η\"][t],\n",
    "                self.variables[\"μ\"][t - 1],\n",
    "            )\n",
    "\n",
    "            # Generate observation noise and calculate expected observations\n",
    "            self.variables[\"ϵ\"][t] = self.N(0, 1, self.L)\n",
    "            self.variables[\"y\"][t] = self.observation_function(\n",
    "                self.variables[\"p_μ\"][t], self.variables[\"p_x\"][t], self.variables[\"ϵ\"][t]\n",
    "            )\n",
    "\n",
    "            # Calculate likelihood using Gaussian observation likelihood\n",
    "            likelihood = self.observation_likelihood(self.observation[t], self.variables[\"p_μ\"][t], self.variables[\"p_x\"][t])\n",
    "            self.variables[\"α\"][t] = likelihood\n",
    "\n",
    "            # Normalize the likelihood to calculate weights\n",
    "            weights = self.variables[\"α\"][t]\n",
    "            weights /= np.sum(weights)\n",
    "\n",
    "            # Resample particles based on weights\n",
    "            cumulative_sum = np.cumsum(weights)\n",
    "            positions = (np.arange(self.L) + np.random.uniform(0, 1)) / self.L\n",
    "            sample_indices = np.searchsorted(cumulative_sum, positions)\n",
    "\n",
    "            # Resample all variables\n",
    "            self.variables[\"x\"][t] = self.variables[\"p_x\"][t, sample_indices]\n",
    "            self.variables[\"μ\"][t] = self.variables[\"p_μ\"][t, sample_indices]\n",
    "            self.variables[\"x̄\"][t] = self.variables[\"p_x̄\"][t, sample_indices]\n",
    "            self.variables[\"μ̄\"][t] = self.variables[\"p_μ̄\"][t, sample_indices]\n",
    "            self.variables[\"ϕ_x\"][t] = self.variables[\"p_ϕ_x\"][t, sample_indices]\n",
    "            self.variables[\"σ_x\"][t] = self.variables[\"p_σ_x\"][t, sample_indices]\n",
    "            self.variables[\"ϕ_μ\"][t] = self.variables[\"p_ϕ_μ\"][t, sample_indices]\n",
    "            self.variables[\"σ_μ\"][t] = self.variables[\"p_σ_μ\"][t, sample_indices]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMSV_EMASO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SMSV_EMASOModel(BaseModel):\n",
    "    \"\"\"\n",
    "    SMSV_EMASO Model class.\n",
    "    \"\"\"\n",
    "    def __init__(self, observation, num_particles, time_steps, σ_μ=1.0):\n",
    "        super().__init__(observation, num_particles, time_steps)\n",
    "        # Parameter\n",
    "        self.α_μ_parameter = np.full(self.L, np.mean(observation[:24]))\n",
    "\n",
    "        # Variables\n",
    "        self.variables.update({\n",
    "            'μ':np.zeros((self.T, self.L)),\n",
    "            \"p_μ\":np.zeros((self.T, self.L)),\n",
    "            \"μ̄\":np.zeros((self.T, self.L)),\n",
    "            \"p_μ̄\":np.zeros((self.T, self.L)),\n",
    "            \"ϕ_μ\": np.zeros((self.T, self.L)),\n",
    "            \"p_ϕ_μ\":np.zeros((self.T, self.L)),\n",
    "            \"σ_μ\":np.zeros((self.T, self.L)),\n",
    "            \"p_σ_μ\":np.zeros((self.T, self.L)),\n",
    "            \"η\": np.zeros((self.T, self.L)),\n",
    "        })\n",
    "        print(self.variables[\"ϕ_μ\"])\n",
    "\n",
    "        # Initialization\n",
    "        self.variables[\"x̄\"][0] = self.U(-1, 5, self.L)\n",
    "        self.variables[\"ϕ_μ\"][0] = self.U(0, 1, self.L)\n",
    "        self.variables[\"ϕ_x\"][0] = 2 * self.B(20, 1.5, self.L) - 1\n",
    "        self.variables[\"σ_x\"][0] = self.U(0, 2, self.L)\n",
    "        \n",
    "        self.variables[\"σ_μ\"][0] = self.U(0, np.std(self.train), self.L)\n",
    "\n",
    "        self.variables[\"x\"][0] = self.N(\n",
    "            self.variables[\"x̄\"][0], \n",
    "            (self.variables[\"σ_x\"][0] ** 2) / (1 - self.variables[\"ϕ_x\"][0] ** 2)\n",
    "        )\n",
    "        self.variables[\"μ\"][0] = self.N(\n",
    "            self.α_μ_parameter, \n",
    "            (self.variables[\"σ_μ\"][0] ** 2) / (1 - self.variables[\"σ_μ\"][0] ** 2)\n",
    "        )   \n",
    "        self.variables[\"ϵ\"][0] = self.N(0, 1, self.L)\n",
    "        self.variables[\"y\"][0] = self.observation_function(\n",
    "            self.variables[\"μ\"][0], self.variables[\"x\"][0], self.variables[\"ϵ\"][0]\n",
    "        )\n",
    "    def μ_transition_function(y_t, ϕ_μ, μ_t):\n",
    "        particles = y_t + ϕ_μ * (μ_t - y_t)\n",
    "        return particles\n",
    "\n",
    "    def particle_filtering(self):\n",
    "        \"\"\"\n",
    "        Particle filtering process for state estimation.\n",
    "        \"\"\"\n",
    "        for t in tqdm(range(1, self.T)):\n",
    "            # SOSS update for prior estimates\n",
    "            self.variables[\"p_x̄\"][t] = self.SOSS_update(self.α_shrink_factor, self.variables[\"x̄\"][t - 1])\n",
    "            self.variables[\"p_ϕ_x\"][t] = self.SOSS_update(self.α_shrink_factor, self.variables[\"ϕ_x\"][t - 1])\n",
    "            self.variables[\"p_σ_x\"][t] = self.SOSS_update(self.α_shrink_factor, self.variables[\"σ_x\"][t - 1])\n",
    "            self.variables[\"p_σ_μ\"][t] = self.SOSS_update(self.α_shrink_factor, self.variables[\"σ_μ\"][t - 1])\n",
    "            self.variables[\"p_ϕ_μ\"][t] = self.SOSS_update(self.α_shrink_factor, self.variables[\"ϕ_μ\"][t - 1])\n",
    "\n",
    "            # Generate system noise and calculate particles for x\n",
    "            self.variables[\"ξ\"][t] = self.N(0, 1, self.L)\n",
    "            self.variables[\"p_x\"][t] = self.x_transition_function(\n",
    "                self.variables[\"p_x̄\"][t],\n",
    "                self.variables[\"p_ϕ_x\"][t],\n",
    "                self.variables[\"p_σ_x\"][t],\n",
    "                self.variables[\"ξ\"][t],\n",
    "                self.variables[\"x\"][t - 1],\n",
    "            )\n",
    "\n",
    "            # Generate system noise and calculate particles for μ\n",
    "            self.variables[\"η\"][t] = self.N(0, 1, self.L)\n",
    "            self.variables[\"p_μ\"][t] = self.μ_transition_function(\n",
    "                self.observation[t - 1],\n",
    "                self.variables[\"p_ϕ_μ\"][t],\n",
    "                self.variables[\"p_σ_μ\"][t],\n",
    "                self.variables[\"η\"][t],\n",
    "                self.variables[\"μ\"][t - 1],\n",
    "            )\n",
    "\n",
    "            # Generate observation noise and calculate expected observations\n",
    "            self.variables[\"ϵ\"][t] = self.N(0, 1, self.L)\n",
    "            self.variables[\"y\"][t] = self.observation_function(\n",
    "                self.variables[\"p_μ\"][t],\n",
    "                self.variables[\"p_x\"][t],\n",
    "                self.variables[\"ϵ\"][t],\n",
    "            )\n",
    "\n",
    "            # Calculate likelihood using Gaussian observation likelihood\n",
    "            likelihood = self.observation_likelihood(self.observation[t], self.variables[\"p_μ\"][t], self.variables[\"p_x\"][t])\n",
    "            self.variables[\"α\"][t] = likelihood\n",
    "\n",
    "            # Normalize the likelihood to calculate weights\n",
    "            weights = self.variables[\"α\"][t]\n",
    "            weights /= np.sum(weights)\n",
    "\n",
    "            # Resample particles based on weights\n",
    "            cumulative_sum = np.cumsum(weights)\n",
    "            positions = (np.arange(self.L) + np.random.uniform(0, 1)) / self.L\n",
    "            sample_indices = np.searchsorted(cumulative_sum, positions)\n",
    "\n",
    "            # Resample all variables\n",
    "            self.variables[\"x\"][t] = self.variables[\"p_x\"][t, sample_indices]\n",
    "            self.variables[\"μ\"][t] = self.variables[\"p_μ\"][t, sample_indices]\n",
    "            self.variables[\"x̄\"][t] = self.variables[\"p_x̄\"][t, sample_indices]\n",
    "            self.variables[\"ϕ_x\"][t] = self.variables[\"p_ϕ_x\"][t, sample_indices]\n",
    "            self.variables[\"σ_x\"][t] = self.variables[\"p_σ_x\"][t, sample_indices]\n",
    "            self.variables[\"ϕ_μ\"][t] = self.variables[\"p_ϕ_μ\"][t, sample_indices]\n",
    "            self.variables[\"σ_μ\"][t] = self.variables[\"p_σ_μ\"][t, sample_indices]\n",
    "    \n",
    "    def plot(self):\n",
    "        \"\"\"\n",
    "        Plots the sequential estimations of parameters and expected returns.\n",
    "        \"\"\"\n",
    "        # Compute median, lower, and upper bounds for each parameter\n",
    "        x̄_median, x̄_lower, x̄_upper = self.compute_stats(self.variables[\"x̄\"])\n",
    "        ϕ_μ_median, ϕ_μ_lower, ϕ_μ_upper = self.compute_stats(self.variables[\"ϕ_μ\"])\n",
    "        ϕ_x_median, ϕ_x_lower, ϕ_x_upper = self.compute_stats(self.variables[\"ϕ_x\"])\n",
    "        σ_x_median, σ_x_lower, σ_x_upper = self.compute_stats(self.variables[\"σ_x\"])\n",
    "        σ_μ_median, σ_μ_lower, σ_μ_upper = self.compute_stats(self.variables[\"σ_μ\"])\n",
    "\n",
    "        # Set up plot style\n",
    "        sns.set_theme(style=\"whitegrid\")  # Use white grid style for better visualization\n",
    "        plt.rcParams[\"axes.grid\"] = True\n",
    "        plt.rcParams[\"axes.grid.axis\"] = \"y\"  # Enable horizontal grid lines only\n",
    "\n",
    "        # Create the figure and axes for a 3x2 grid of subplots\n",
    "        fig, axes = plt.subplots(3, 2, figsize=(12, 10))\n",
    "        dates = self.returns.index  # Dates for x-axis, assuming self.returns contains the returns DataFrame\n",
    "\n",
    "        # Sequential estimations of x̄\n",
    "        axes[0, 0].plot(dates, x̄_median, label=\"Median\", color=\"cornflowerblue\")\n",
    "        axes[0, 0].plot(dates, x̄_lower, linestyle=\"dotted\", color=\"orange\")\n",
    "        axes[0, 0].plot(dates, x̄_upper, linestyle=\"dotted\", color=\"orange\")\n",
    "        axes[0, 0].set_title(\"Sequential estimations of parameter $\\overline{x}$\")\n",
    "        axes[0, 0].set_ylim(-2, 6)\n",
    "\n",
    "        # Sequential estimations of ϕ_μ\n",
    "        axes[0, 1].plot(dates, ϕ_μ_median, label=\"Median\", color=\"cornflowerblue\")\n",
    "        axes[0, 1].plot(dates, ϕ_μ_lower, linestyle=\"dotted\", color=\"orange\")\n",
    "        axes[0, 1].plot(dates, ϕ_μ_upper, linestyle=\"dotted\", color=\"orange\")\n",
    "        axes[0, 1].set_title(\"Sequential estimations of parameter $\\phi_\\mu$\")\n",
    "        axes[0, 1].set_ylim(0, 1.2)\n",
    "\n",
    "        # Sequential estimations of ϕ_x\n",
    "        axes[1, 0].plot(dates, ϕ_x_median, label=\"Median\", color=\"cornflowerblue\")\n",
    "        axes[1, 0].plot(dates, ϕ_x_lower, linestyle=\"dotted\", color=\"orange\")\n",
    "        axes[1, 0].plot(dates, ϕ_x_upper, linestyle=\"dotted\", color=\"orange\")\n",
    "        axes[1, 0].set_title(\"Sequential estimations of parameter $\\phi_x$\")\n",
    "        axes[1, 0].set_ylim(0.4, 1.1)\n",
    "\n",
    "        # Sequential estimations of σ_μ\n",
    "        axes[1, 1].plot(dates, σ_μ_median, label=\"Median\", color=\"cornflowerblue\")\n",
    "        axes[1, 1].plot(dates, σ_μ_lower, linestyle=\"dotted\", color=\"orange\")\n",
    "        axes[1, 1].plot(dates, σ_μ_upper, linestyle=\"dotted\", color=\"orange\")\n",
    "        axes[1, 1].set_title(\"Sequential estimations of parameter $\\sigma_\\mu$\")\n",
    "        axes[1, 1].set_ylim(0, 4.5)\n",
    "\n",
    "        # Sequential estimations of σ_x\n",
    "        axes[2, 0].plot(dates, σ_x_median, label=\"Median\", color=\"cornflowerblue\")\n",
    "        axes[2, 0].plot(dates, σ_x_lower, linestyle=\"dotted\", color=\"orange\")\n",
    "        axes[2, 0].plot(dates, σ_x_upper, linestyle=\"dotted\", color=\"orange\")\n",
    "        axes[2, 0].set_title(\"Sequential estimations of parameter $\\sigma_x$\")\n",
    "        axes[2, 0].set_ylim(0, 2.5)\n",
    "\n",
    "        # Expected returns\n",
    "        observation = self.observation  # Assuming self.observation contains the observed returns\n",
    "        y_median = np.median(self.variables[\"y\"], axis=1)  # Median of expected returns\n",
    "        axes[2, 1].plot(dates[48:], observation[48:], linestyle=\"dotted\", color=\"grey\", label=\"Observed\")\n",
    "        axes[2, 1].plot(dates[48:], y_median[48:], color=\"orange\", label=\"Expected\")\n",
    "        axes[2, 1].set_title(\"Expected Returns\")\n",
    "        axes[2, 1].set_ylim(-20, 15)\n",
    "\n",
    "        # Add legends to the first subplot in each row\n",
    "        for i in range(3):\n",
    "            axes[i, 0].legend()\n",
    "\n",
    "        # Adjust layout for better appearance\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_name, observation, num_particles, time_steps, **kwargs):\n",
    "    \"\"\"\n",
    "    Factory function to get the appropriate model.\n",
    "    \"\"\"\n",
    "    models = {\n",
    "        \"CMSV\": CMSVModel(observation, num_particles, time_steps, **kwargs),\n",
    "        \"SMSV\": SMSVModel(observation, num_particles, time_steps, **kwargs),\n",
    "        \"SMSV+EMA\": SMSV_EMAModel(observation, num_particles, time_steps, **kwargs),\n",
    "        \"SMSV+EMASO\": SMSV_EMASOModel(observation, num_particles, time_steps, **kwargs),\n",
    "    }\n",
    "    if model_name not in models:\n",
    "        raise ValueError(f\"Model '{model_name}' is not recognized.\")\n",
    "    return models[model_name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ϕ_μ'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m     data \u001b[39m=\u001b[39m yf\u001b[39m.\u001b[39mdownload(ticker, start\u001b[39m=\u001b[39mstart_date, end\u001b[39m=\u001b[39mend_date, interval\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m1mo\u001b[39m\u001b[39m'\u001b[39m, progress\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)[\u001b[39m'\u001b[39m\u001b[39mAdj Close\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     13\u001b[0m     returns \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mpct_change()\u001b[39m.\u001b[39mdropna() \u001b[39m*\u001b[39m \u001b[39m100\u001b[39m  \u001b[39m# Calculate monthly returns\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m model \u001b[39m=\u001b[39m get_model(SMSV_EMASOModel, returns, num_particles \u001b[39m=\u001b[39;49m \u001b[39m1_000_000\u001b[39;49m, time_steps \u001b[39m=\u001b[39;49m \u001b[39m155\u001b[39;49m )\n",
      "Cell \u001b[0;32mIn[35], line 7\u001b[0m, in \u001b[0;36mget_model\u001b[0;34m(model_name, observation, num_particles, time_steps, **kwargs)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_model\u001b[39m(model_name, observation, num_particles, time_steps, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m      2\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m    Factory function to get the appropriate model.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     models \u001b[39m=\u001b[39m {\n\u001b[1;32m      6\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCMSV\u001b[39m\u001b[39m\"\u001b[39m: CMSVModel(observation, num_particles, time_steps, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs),\n\u001b[0;32m----> 7\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSMSV\u001b[39m\u001b[39m\"\u001b[39m: SMSVModel(observation, num_particles, time_steps, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs),\n\u001b[1;32m      8\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSMSV+EMA\u001b[39m\u001b[39m\"\u001b[39m: SMSV_EMAModel(observation, num_particles, time_steps, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs),\n\u001b[1;32m      9\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSMSV+EMASO\u001b[39m\u001b[39m\"\u001b[39m: SMSV_EMASOModel(observation, num_particles, time_steps, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs),\n\u001b[1;32m     10\u001b[0m     }\n\u001b[1;32m     11\u001b[0m     \u001b[39mif\u001b[39;00m model_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m models:\n\u001b[1;32m     12\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m is not recognized.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[20], line 24\u001b[0m, in \u001b[0;36mSMSVModel.__init__\u001b[0;34m(self, observation, num_particles, time_steps, β)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvariables[\u001b[39m\"\u001b[39m\u001b[39mμ̄\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mU(\u001b[39m-\u001b[39m\u001b[39m5\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mL)\n\u001b[1;32m     23\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvariables[\u001b[39m\"\u001b[39m\u001b[39mx̄\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mU(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mL)\n\u001b[0;32m---> 24\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvariables[\u001b[39m\"\u001b[39;49m\u001b[39mϕ_μ\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mU(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mL)\n\u001b[1;32m     25\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvariables[\u001b[39m\"\u001b[39m\u001b[39mσ_μ\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mU(\u001b[39m0\u001b[39m, np\u001b[39m.\u001b[39mstd(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mL)\n\u001b[1;32m     26\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvariables[\u001b[39m\"\u001b[39m\u001b[39mϕ_x\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mB(\u001b[39m20\u001b[39m, \u001b[39m1.5\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mL) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ϕ_μ'"
     ]
    }
   ],
   "source": [
    "tickers = [\n",
    "    \"^N225\",    # S&P 500 Index\n",
    "      # iShares U.S. Real Estate ETF (Morgan Stanley REIT Index)\n",
    "]\n",
    "\n",
    "# Download monthly returns data for the last 14 years\n",
    "start_date = \"2003-03-01\"\n",
    "end_date = \"2016-04-01\"\n",
    "\n",
    "# Fetch monthly data for each ticker\n",
    "for ticker in tickers:\n",
    "    data = yf.download(ticker, start=start_date, end=end_date, interval='1mo', progress=False)['Adj Close']\n",
    "    returns = data.pct_change().dropna() * 100  # Calculate monthly returns\n",
    "\n",
    "model = get_model(SMSV_EMASOModel, returns, num_particles = 1_000_000, time_steps = 155 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
